<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>bob.measure.credible_region &mdash; bob.measure 4.2.4b0 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/plot_directive.css" type="text/css" />
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> bob.measure
            <img src="../../../_static/logo.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                4.2.4b0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../guide.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ci.html">Credible and Confidence Intervals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cli.html">Command-Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../references.html">References</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">bob.measure</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../index.html">Module code</a> &raquo;</li>
      <li>bob.measure.credible_region</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for bob.measure.credible_region</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python</span>
<span class="c1"># coding=utf-8</span>

<span class="sd">&quot;&quot;&quot;Functions to evalute the (Bayesian) credible region of measures</span>

<span class="sd">(Bayesian) credible region interpretation, with 95% coverage: The probability</span>
<span class="sd">that the true proportion will lie within the 95% credible interval is 0.95.</span>

<span class="sd">Contrary to frequentist approaches, in which one can only say that if the test</span>
<span class="sd">were repeated an infinite number of times, and one constructed a confidence</span>
<span class="sd">interval each time, then X% of the confidence intervals would contain the true</span>
<span class="sd">rate, here we can say that given our observed data, there is a X% probability</span>
<span class="sd">that the true value of :math:`k/n` falls within the provided interval.</span>

<span class="sd">See a discussion in `Five Confidence Intervals for Proportions That You</span>
<span class="sd">Should Know About &lt;ci-evaluation_&gt;`_ for a study on coverage for most common</span>
<span class="sd">methods.</span>

<span class="sd">.. note::</span>

<span class="sd">   For a disambiguation with `Confidence Interval &lt;confidence-interval_&gt;`_ (the</span>
<span class="sd">   frequentist approach), read `Credible Regions or Intervals</span>
<span class="sd">   &lt;credible-interval_&gt;`_.</span>

<span class="sd">.. include:: ../links.rst</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">numbers</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">numpy.random</span>
<span class="kn">import</span> <span class="nn">scipy.special</span>


<div class="viewcode-block" id="beta"><a class="viewcode-back" href="../../../api/bob.measure.credible_region.html#bob.measure.credible_region.beta">[docs]</a><span class="k">def</span> <span class="nf">beta</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">coverage</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the mode, upper and lower bounds of the equal-tailed credible</span>
<span class="sd">    region of a probability estimate following Bernoulli trials.</span>

<span class="sd">    This technique is (not) very conservative - in most of the cases, coverage</span>
<span class="sd">    closer to the extremes (0 or 1) is lower than expected (but still greater</span>
<span class="sd">    than 85%).</span>

<span class="sd">    This implementation is based on [GOUTTE-2005]_.  It assumes :math:`k`</span>
<span class="sd">    successes and :math:`l` failures (:math:`n = k+l` total trials) are issued</span>
<span class="sd">    from a series of Bernoulli trials (likelihood is binomial).  The posterior</span>
<span class="sd">    is derivated using the Bayes Theorem with a beta prior.  As there is no</span>
<span class="sd">    reason to favour high vs.  low precision, we use a symmetric Beta prior</span>
<span class="sd">    (:math:`\\alpha=\\beta`):</span>

<span class="sd">    .. math::</span>

<span class="sd">       P(p|k,n) &amp;= \\frac{P(k,n|p)P(p)}{P(k,n)} \\\\</span>
<span class="sd">       P(p|k,n) &amp;= \\frac{\\frac{n!}{k!(n-k)!}p^{k}(1-p)^{n-k}P(p)}{P(k)} \\\\</span>
<span class="sd">       P(p|k,n) &amp;= \\frac{1}{B(k+\\alpha, n-k+\beta)}p^{k+\\alpha-1}(1-p)^{n-k+\\beta-1} \\\\</span>
<span class="sd">       P(p|k,n) &amp;= \\frac{1}{B(k+\\alpha, n-k+\\alpha)}p^{k+\\alpha-1}(1-p)^{n-k+\\alpha-1}</span>

<span class="sd">    The mode for this posterior (also the maximum a posteriori) is:</span>

<span class="sd">    .. math::</span>

<span class="sd">       \\text{mode}(p) = \\frac{k+\\lambda-1}{n+2\\lambda-2}</span>

<span class="sd">    Concretely, the prior may be flat (all rates are equally likely,</span>
<span class="sd">    :math:`\\lambda=1`) or we may use Jeoffrey&#39;s prior (:math:`\\lambda=0.5`),</span>
<span class="sd">    that is invariant through re-parameterisation.  Jeffrey&#39;s prior indicate</span>
<span class="sd">    that rates close to zero or one are more likely.</span>

<span class="sd">    The mode above works if :math:`k+{\\alpha},n-k+{\\alpha} &gt; 1`, which is</span>
<span class="sd">    usually the case for a resonably well tunned system, with more than a few</span>
<span class="sd">    samples for analysis.  In the limit of the system performance, :math:`k`</span>
<span class="sd">    may be 0, which will make the mode become zero.</span>

<span class="sd">    For our purposes, it may be more suitable to represent :math:`n = k + l`,</span>
<span class="sd">    with :math:`k`, the number of successes and :math:`l`, the number of</span>
<span class="sd">    failures in the binomial experiment, and find this more suitable</span>
<span class="sd">    representation:</span>

<span class="sd">    .. math::</span>

<span class="sd">       P(p|k,l) &amp;= \\frac{1}{B(k+\\alpha, l+\\alpha)}p^{k+\\alpha-1}(1-p)^{l+\\alpha-1} \\\\</span>
<span class="sd">       \\text{mode}(p) &amp;= \\frac{k+\\lambda-1}{k+l+2\\lambda-2}</span>

<span class="sd">    This can be mapped to most rates calculated in the context of binary</span>
<span class="sd">    classification this way:</span>

<span class="sd">    * Precision or Positive-Predictive Value (PPV): p = TP/(TP+FP), so k=TP, l=FP</span>
<span class="sd">    * Recall, Sensitivity, or True Positive Rate: r = TP/(TP+FN), so k=TP, l=FN</span>
<span class="sd">    * Specificity or True Negative Rage: s = TN/(TN+FP), so k=TN, l=FP</span>
<span class="sd">    * F1-score: f1 = 2TP/(2TP+FP+FN), so k=2TP, l=FP+FN</span>
<span class="sd">    * Accuracy: acc = TP+TN/(TP+TN+FP+FN), so k=TP+TN, l=FP+FN</span>
<span class="sd">    * Jaccard: j = TP/(TP+FP+FN), so k=TP, l=FP+FN</span>


<span class="sd">    Parameters</span>
<span class="sd">    ==========</span>

<span class="sd">    k : int, numpy.ndarray (int, 1D)</span>
<span class="sd">        Number of successes observed on the experiment</span>

<span class="sd">    l : int, numpy.ndarray (int, 1D)</span>
<span class="sd">        Number of failures observed on the experiment</span>

<span class="sd">    lambda_ : :py:class:`float`, Optional</span>
<span class="sd">        The parameterisation of the Beta prior to consider. Use</span>
<span class="sd">        :math:`\\lambda=1` for a flat prior.  Use :math:`\\lambda=0.5` for</span>
<span class="sd">        Jeffrey&#39;s prior.  If unsure, use 0.5.</span>

<span class="sd">    coverage : :py:class:`float`, Optional</span>
<span class="sd">        A floating-point number between 0 and 1.0 indicating the</span>
<span class="sd">        coverage you&#39;re expecting.  A value of 0.95 will ensure 95%</span>
<span class="sd">        of the area under the probability density of the posterior</span>
<span class="sd">        is covered by the returned equal-tailed interval.</span>


<span class="sd">    Returns</span>
<span class="sd">    =======</span>

<span class="sd">    mean : float, numpy.ndarray (float, 1D)</span>
<span class="sd">        The mean of the posterior distribution</span>

<span class="sd">    mode : float, numpy.ndarray (float, 1D)</span>
<span class="sd">        The mode of the posterior distribution</span>

<span class="sd">    lower, upper: float, numpy.ndarray (float, 1D)</span>
<span class="sd">        The lower and upper bounds of the credible region</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">is_scalar</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">is_scalar</span><span class="p">:</span>
        <span class="c1"># make it an array</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">k</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,))</span>
        <span class="n">l</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">l</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,))</span>

    <span class="c1"># we return the equally-tailed range</span>
    <span class="n">right</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">coverage</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>  <span class="c1"># half-width in each side</span>
    <span class="n">lower</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">betaincinv</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">l</span> <span class="o">+</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">right</span><span class="p">)</span>
    <span class="n">upper</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">betaincinv</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">l</span> <span class="o">+</span> <span class="n">lambda_</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">right</span><span class="p">)</span>

    <span class="c1"># evaluate mean and mode (https://en.wikipedia.org/wiki/Beta_distribution)</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">k</span> <span class="o">+</span> <span class="n">lambda_</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="n">l</span> <span class="o">+</span> <span class="n">lambda_</span>

    <span class="n">E</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">/</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">+</span> <span class="n">beta</span><span class="p">)</span>

    <span class="c1"># the mode of a beta distribution is a bit tricky</span>
    <span class="n">mode</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">lower</span><span class="p">)</span>
    <span class="n">cond</span> <span class="o">=</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">beta</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">mode</span><span class="p">[</span><span class="n">cond</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">alpha</span><span class="p">[</span><span class="n">cond</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">alpha</span><span class="p">[</span><span class="n">cond</span><span class="p">]</span> <span class="o">+</span> <span class="n">beta</span><span class="p">[</span><span class="n">cond</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
    <span class="c1"># In the case of precision, if the threshold is close to 1.0, both TP</span>
    <span class="c1"># and FP can be zero, which may cause this condition to be reached, if</span>
    <span class="c1"># the prior is exactly 1 (flat prior).  This is a weird situation,</span>
    <span class="c1"># because effectively we are trying to compute the posterior when the</span>
    <span class="c1"># total number of experiments is zero.  So, only the prior counts - but</span>
    <span class="c1"># the prior is flat, so we should just pick a value.  We choose the</span>
    <span class="c1"># middle of the range.</span>
    <span class="c1"># conda = alpha == 1 and beta == 1</span>
    <span class="c1"># mode[cond] = 0.0</span>
    <span class="c1"># conda = alpha &lt;= 1 and beta &gt; 1</span>
    <span class="c1"># mode[cond] = 0.0</span>
    <span class="n">mode</span><span class="p">[(</span><span class="n">alpha</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">beta</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="c1"># else: #elif alpha &lt; 1 and beta &lt; 1:</span>
    <span class="c1"># in the case of precision, if the threshold is close to 1.0, both TP</span>
    <span class="c1"># and FP can be zero, which may cause this condition to be reached, if</span>
    <span class="c1"># the prior is smaller than 1.  This is a weird situation, because</span>
    <span class="c1"># effectively we are trying to compute the posterior when the total</span>
    <span class="c1"># number of experiments is zero.  So, only the prior counts - but the</span>
    <span class="c1"># prior is bimodal, so we should just pick a value.  We choose the</span>
    <span class="c1"># left of the range.</span>
    <span class="c1"># n.b.: could also be 1.0 as the prior is bimodal</span>
    <span class="c1"># mode[alpha &lt; 1 and beta &lt; 1] = 0.0</span>

    <span class="k">if</span> <span class="n">is_scalar</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">E</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">mode</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">lower</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">upper</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">E</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span></div>


<div class="viewcode-block" id="beta_posterior"><a class="viewcode-back" href="../../../api/bob.measure.credible_region.html#bob.measure.credible_region.beta_posterior">[docs]</a><span class="k">def</span> <span class="nf">beta_posterior</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">nb_samples</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Simulates the beta posterior of a system with the provided markings</span>

<span class="sd">    This implementation is based on [GOUTTE-2005]_, equation 7.</span>

<span class="sd">    Figures of merit that are supported by this procedure are those which have</span>
<span class="sd">    the form :math:`v = k / (k + l)`:</span>

<span class="sd">    * Precision or Positive-Predictive Value (PPV): :math:`p = TP/(TP+FP)`, so</span>
<span class="sd">      :math:`k=TP`, :math:`l=FP`</span>
<span class="sd">    * Recall, Sensitivity, or True Positive Rate: :math:`r = TP/(TP+FN)`, so</span>
<span class="sd">      :math:`k=TP`, :math:`l=FN`</span>
<span class="sd">    * Specificity or True Negative Rage: :math:`s = TN/(TN+FP)`, so :math:`k=TN`,</span>
<span class="sd">      :math:`l=FP`</span>
<span class="sd">    * Accuracy: :math:`acc = TP+TN/(TP+TN+FP+FN)`, so :math:`k=TP+TN`,</span>
<span class="sd">      :math:`l=FP+FN`</span>
<span class="sd">    * Jaccard Index: :math:`j = TP/(TP+FP+FN)`, so :math:`k=TP`, :math:`l=FP+FN`</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    k : int</span>
<span class="sd">        Depends on the figure of merit being considered (see above)</span>

<span class="sd">    l : int</span>
<span class="sd">        Depends on the figure of merit being considered (see above)</span>

<span class="sd">    lambda_ : float</span>
<span class="sd">        The parameterisation of the Beta prior to consider. Use</span>
<span class="sd">        :math:`\lambda=1` for a flat prior.  Use :math:`\lambda=0.5` for</span>
<span class="sd">        Jeffrey&#39;s prior.</span>

<span class="sd">    nb_samples : int</span>
<span class="sd">        number of generated gamma distribution values</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>

<span class="sd">    variates : numpy.ndarray</span>
<span class="sd">        An array with size ``nb_samples`` containing a realization of equation 7.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="n">lambda_</span><span class="p">),</span> <span class="n">b</span><span class="o">=</span><span class="p">(</span><span class="n">l</span> <span class="o">+</span> <span class="n">lambda_</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="n">nb_samples</span><span class="p">)</span></div>


<div class="viewcode-block" id="compare_beta_posteriors"><a class="viewcode-back" href="../../../api/bob.measure.credible_region.html#bob.measure.credible_region.compare_beta_posteriors">[docs]</a><span class="k">def</span> <span class="nf">compare_beta_posteriors</span><span class="p">(</span><span class="n">k1</span><span class="p">,</span> <span class="n">l1</span><span class="p">,</span> <span class="n">k2</span><span class="p">,</span> <span class="n">l2</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">nb_samples</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the probability that system 1 is better than system 2 for a given</span>
<span class="sd">    figure of merit.</span>

<span class="sd">    This implementation is based on [GOUTTE-2005]_.</span>

<span class="sd">    Figures of merit that are supported by this procedure are those which have</span>
<span class="sd">    the form :math:`v = k / (k + l)`:</span>

<span class="sd">    * Precision or Positive-Predictive Value (PPV): :math:`p = TP/(TP+FP)`, so</span>
<span class="sd">      :math:`k=TP`, :math:`l=FP`</span>
<span class="sd">    * Recall, Sensitivity, or True Positive Rate: :math:`r = TP/(TP+FN)`, so</span>
<span class="sd">      :math:`k=TP`, :math:`l=FN`</span>
<span class="sd">    * Specificity or True Negative Rage: :math:`s = TN/(TN+FP)`, so :math:`k=TN`,</span>
<span class="sd">      :math:`l=FP`</span>
<span class="sd">    * Accuracy: :math:`acc = TP+TN/(TP+TN+FP+FN)`, so :math:`k=TP+TN`,</span>
<span class="sd">      :math:`l=FP+FN`</span>
<span class="sd">    * Jaccard Index: :math:`j = TP/(TP+FP+FN)`, so :math:`k=TP`, :math:`l=FP+FN`</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    k1/2 : int</span>
<span class="sd">        Depends on the figure of merit being considered (see above)</span>

<span class="sd">    l1/2 : int</span>
<span class="sd">        Depends on the figure of merit being considered (see above)</span>

<span class="sd">    lambda_ : float</span>
<span class="sd">        The parameterisation of the Beta prior to consider. Use</span>
<span class="sd">        :math:`\lambda=1` for a flat prior.  Use :math:`\lambda=0.5` for</span>
<span class="sd">        Jeffrey&#39;s prior.  If unsure, use 0.5.</span>

<span class="sd">    nb_samples : int</span>
<span class="sd">        number of generated beta distribution values</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>

<span class="sd">    prob : float</span>
<span class="sd">        A number between 0.0 and 1.0 that describes the probability that the</span>
<span class="sd">        first system has a bigger measurement than the second</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">v1</span> <span class="o">=</span> <span class="n">beta_posterior</span><span class="p">(</span><span class="n">k1</span><span class="p">,</span> <span class="n">l1</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">nb_samples</span><span class="p">)</span>
    <span class="n">v2</span> <span class="o">=</span> <span class="n">beta_posterior</span><span class="p">(</span><span class="n">k2</span><span class="p">,</span> <span class="n">l2</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">nb_samples</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">v1</span> <span class="o">&gt;</span> <span class="n">v2</span><span class="p">)</span> <span class="o">/</span> <span class="n">nb_samples</span></div>


<div class="viewcode-block" id="f1_posterior"><a class="viewcode-back" href="../../../api/bob.measure.credible_region.html#bob.measure.credible_region.f1_posterior">[docs]</a><span class="k">def</span> <span class="nf">f1_posterior</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">nb_samples</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Simulates the F1-score posterior of a system with the provided markings</span>

<span class="sd">    This implementation is based on [GOUTTE-2005]_, equation 11.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    tp : int</span>
<span class="sd">        True positive count, AKA &quot;hit&quot;</span>

<span class="sd">    fp : int</span>
<span class="sd">        False positive count, AKA &quot;false alarm&quot;, or &quot;Type I error&quot;</span>

<span class="sd">    fn : int</span>
<span class="sd">        False Negative count, AKA &quot;miss&quot;, or &quot;Type II error&quot;</span>

<span class="sd">    lambda_ : float</span>
<span class="sd">        The parameterisation of the Beta prior to consider. Use</span>
<span class="sd">        :math:`\lambda=1` for a flat prior.  Use :math:`\lambda=0.5` for</span>
<span class="sd">        Jeffrey&#39;s prior.  If unsure, use 0.5.</span>

<span class="sd">    nb_samples : int</span>
<span class="sd">        number of generated gamma distribution values</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>

<span class="sd">    variates : numpy.ndarray</span>
<span class="sd">        An array with size ``nb_samples`` containing a realization of equation</span>
<span class="sd">        11.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">u</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">lambda_</span><span class="p">),</span> <span class="n">scale</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">nb_samples</span><span class="p">)</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">fp</span> <span class="o">+</span> <span class="n">fn</span> <span class="o">+</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">lambda_</span><span class="p">)),</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">nb_samples</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">u</span> <span class="o">/</span> <span class="p">(</span><span class="n">u</span> <span class="o">+</span> <span class="n">v</span><span class="p">)</span></div>


<div class="viewcode-block" id="compare_f1_scores"><a class="viewcode-back" href="../../../api/bob.measure.credible_region.html#bob.measure.credible_region.compare_f1_scores">[docs]</a><span class="k">def</span> <span class="nf">compare_f1_scores</span><span class="p">(</span><span class="n">tp1</span><span class="p">,</span> <span class="n">fp1</span><span class="p">,</span> <span class="n">fn1</span><span class="p">,</span> <span class="n">tp2</span><span class="p">,</span> <span class="n">fp2</span><span class="p">,</span> <span class="n">fn2</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">nb_samples</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the probability that the F1-score from 1 system is bigger than the</span>
<span class="sd">    F1-score of a second system.</span>

<span class="sd">    This implementation is based on [GOUTTE-2005]_.</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    tp1/2 : int</span>
<span class="sd">        True positive count, AKA &quot;hit&quot;</span>

<span class="sd">    fp1/2 : int</span>
<span class="sd">        False positive count, AKA &quot;false alarm&quot;, or &quot;Type I error&quot;</span>

<span class="sd">    fn1/2 : int</span>
<span class="sd">        False Negative count, AKA &quot;miss&quot;, or &quot;Type II error&quot;</span>

<span class="sd">    lambda_ : float</span>
<span class="sd">        The parameterisation of the Beta prior to consider. Use</span>
<span class="sd">        :math:`\lambda=1` for a flat prior.  Use :math:`\lambda=0.5` for</span>
<span class="sd">        Jeffrey&#39;s prior.</span>

<span class="sd">    nb_samples : int</span>
<span class="sd">        number of generated gamma distribution values</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>

<span class="sd">    prob : float</span>
<span class="sd">        A number between 0.0 and 1.0 that describes the probability that the</span>
<span class="sd">        first system has a bigger F1-score than the second</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_posterior</span><span class="p">(</span><span class="n">tp1</span><span class="p">,</span> <span class="n">fp1</span><span class="p">,</span> <span class="n">fn1</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">nb_samples</span><span class="p">)</span>
    <span class="n">f2</span> <span class="o">=</span> <span class="n">f1_posterior</span><span class="p">(</span><span class="n">tp2</span><span class="p">,</span> <span class="n">fp2</span><span class="p">,</span> <span class="n">fn2</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">nb_samples</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">f1</span> <span class="o">&gt;</span> <span class="n">f2</span><span class="p">)</span> <span class="o">/</span> <span class="n">nb_samples</span></div>


<div class="viewcode-block" id="f1_score"><a class="viewcode-back" href="../../../api/bob.measure.credible_region.html#bob.measure.credible_region.f1_score">[docs]</a><span class="k">def</span> <span class="nf">f1_score</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">coverage</span><span class="p">,</span> <span class="n">nb_samples</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the mean, mode, upper and lower bounds of the credible</span>
<span class="sd">    region of the F1 score.</span>

<span class="sd">    This implementation is based on [GOUTTE-2005]_.</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    tp : int</span>
<span class="sd">        True positive count, AKA &quot;hit&quot;</span>

<span class="sd">    fp : int</span>
<span class="sd">        False positive count, AKA &quot;false alarm&quot;, or &quot;Type I error&quot;</span>

<span class="sd">    fn : int</span>
<span class="sd">        False Negative count, AKA &quot;miss&quot;, or &quot;Type II error&quot;</span>

<span class="sd">    lambda_ : float</span>
<span class="sd">        The parameterisation of the Beta prior to consider. Use</span>
<span class="sd">        :math:`\lambda=1` for a flat prior.  Use :math:`\lambda=0.5` for</span>
<span class="sd">        Jeffrey&#39;s prior.</span>

<span class="sd">    coverage : float</span>
<span class="sd">        A floating-point number between 0 and 1.0 indicating the coverage</span>
<span class="sd">        you&#39;re expecting.  A value of 0.95 will ensure 95% of the area under</span>
<span class="sd">        the probability density of the posterior is covered by the returned</span>
<span class="sd">        equal-tailed interval.</span>

<span class="sd">    nb_samples : int</span>
<span class="sd">        number of generated gamma distribution values</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>

<span class="sd">    f1_score : (float, float, float, float)</span>
<span class="sd">        F1, mean, mode and credible intervals (95% CI). See `F1-score</span>
<span class="sd">        &lt;https://en.wikipedia.org/wiki/F1_score&gt;`_.  It corresponds</span>
<span class="sd">        arithmetically to ``2*P*R/(P+R)`` or ``2*tp/(2*tp+fp+fn)``.  The F1 or</span>
<span class="sd">        Dice score depends on a TP-only numerator, similarly to the Jaccard</span>
<span class="sd">        index.  For regions where there are no annotations, the F1-score will</span>
<span class="sd">        always be zero, irrespective of the model output.  Accuracy may be a</span>
<span class="sd">        better proxy if one needs to consider the true abscence of annotations</span>
<span class="sd">        in a region as part of the measure.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">scores</span> <span class="o">=</span> <span class="n">f1_posterior</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">nb_samples</span><span class="p">)</span>

    <span class="n">left_half</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">coverage</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>  <span class="c1"># size of excluded (half) area</span>
    <span class="n">sorted_scores</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>

    <span class="c1"># n.b.: we return the equally tailed range</span>

    <span class="c1"># calculates position of score which would exclude the left_half (left)</span>
    <span class="n">lower_index</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">nb_samples</span> <span class="o">*</span> <span class="n">left_half</span><span class="p">))</span>

    <span class="c1"># calculates position of score which would exclude the left_half (right)</span>
    <span class="n">upper_index</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">nb_samples</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">left_half</span><span class="p">)))</span>

    <span class="n">lower</span> <span class="o">=</span> <span class="n">sorted_scores</span><span class="p">[</span><span class="n">lower_index</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">upper</span> <span class="o">=</span> <span class="n">sorted_scores</span><span class="p">[</span><span class="n">upper_index</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">),</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="n">scores</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span></div>


<div class="viewcode-block" id="measures"><a class="viewcode-back" href="../../../api/bob.measure.credible_region.html#bob.measure.credible_region.measures">[docs]</a><span class="k">def</span> <span class="nf">measures</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">coverage</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculates mean and mode from true/false positive and negative counts</span>
<span class="sd">    with credible regions</span>

<span class="sd">    This function can return bayesian estimates of standard machine learning</span>
<span class="sd">    measures from true and false positive counts of positives and negatives.</span>
<span class="sd">    For a thorough look into these and alternate names for the returned values,</span>
<span class="sd">    please check Wikipedia&#39;s entry on `Precision and Recall</span>
<span class="sd">    &lt;https://en.wikipedia.org/wiki/Precision_and_recall&gt;`_.  See</span>
<span class="sd">    :py:func:`beta_credible_region` for details on the calculation of returned</span>
<span class="sd">    values.</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    tp : int</span>
<span class="sd">        True positive count, AKA &quot;hit&quot;</span>

<span class="sd">    fp : int</span>
<span class="sd">        False positive count, AKA &quot;false alarm&quot;, or &quot;Type I error&quot;</span>

<span class="sd">    tn : int</span>
<span class="sd">        True negative count, AKA &quot;correct rejection&quot;</span>

<span class="sd">    fn : int</span>
<span class="sd">        False Negative count, AKA &quot;miss&quot;, or &quot;Type II error&quot;</span>

<span class="sd">    lambda_ : float</span>
<span class="sd">        The parameterisation of the Beta prior to consider. Use</span>
<span class="sd">        :math:`\lambda=1` for a flat prior.  Use :math:`\lambda=0.5` for</span>
<span class="sd">        Jeffrey&#39;s prior.</span>

<span class="sd">    coverage : float</span>
<span class="sd">        A floating-point number between 0 and 1.0 indicating the coverage</span>
<span class="sd">        you&#39;re expecting.  A value of 0.95 will ensure 95% of the area under</span>
<span class="sd">        the probability density of the posterior is covered by the returned</span>
<span class="sd">        equal-tailed interval.</span>



<span class="sd">    Returns</span>
<span class="sd">    -------</span>

<span class="sd">    precision : (float, float, float, float)</span>
<span class="sd">        P, AKA positive predictive value (PPV), mean, mode and credible</span>
<span class="sd">        intervals (95% CI).  It corresponds arithmetically to ``tp/(tp+fp)``.</span>

<span class="sd">    recall : (float, float, float, float)</span>
<span class="sd">        R, AKA sensitivity, hit rate, or true positive rate (TPR), mean, mode</span>
<span class="sd">        and credible intervals (95% CI).  It corresponds arithmetically to</span>
<span class="sd">        ``tp/(tp+fn)``.</span>

<span class="sd">    specificity : (float, float, float, float)</span>
<span class="sd">        S, AKA selectivity or true negative rate (TNR), mean, mode and credible</span>
<span class="sd">        intervals (95% CI).  It corresponds arithmetically to ``tn/(tn+fp)``.</span>

<span class="sd">    accuracy : (float, float, float, float)</span>
<span class="sd">        A, mean, mode and credible intervals (95% CI).  See `Accuracy</span>
<span class="sd">        &lt;https://en.wikipedia.org/wiki/Evaluation_of_binary_classifiers&gt;`_. is</span>
<span class="sd">        the proportion of correct predictions (both true positives and true</span>
<span class="sd">        negatives) among the total number of pixels examined.  It corresponds</span>
<span class="sd">        arithmetically to ``(tp+tn)/(tp+tn+fp+fn)``.  This measure includes</span>
<span class="sd">        both true-negatives and positives in the numerator, what makes it</span>
<span class="sd">        sensitive to data or regions without annotations.</span>

<span class="sd">    jaccard : (float, float, float, float)</span>
<span class="sd">        J, mean, mode and credible intervals (95% CI).  See `Jaccard Index or</span>
<span class="sd">        Similarity &lt;https://en.wikipedia.org/wiki/Jaccard_index&gt;`_.  It</span>
<span class="sd">        corresponds arithmetically to ``tp/(tp+fp+fn)``.  The Jaccard index</span>
<span class="sd">        depends on a TP-only numerator, similarly to the F1 score.  For regions</span>
<span class="sd">        where there are no annotations, the Jaccard index will always be zero,</span>
<span class="sd">        irrespective of the model output.  Accuracy may be a better proxy if</span>
<span class="sd">        one needs to consider the true abscence of annotations in a region as</span>
<span class="sd">        part of the measure.</span>

<span class="sd">    f1_score : (float, float, float, float)</span>
<span class="sd">        F1, mean, mode and credible intervals (95% CI). See `F1-score</span>
<span class="sd">        &lt;https://en.wikipedia.org/wiki/F1_score&gt;`_.  It corresponds</span>
<span class="sd">        arithmetically to ``2*P*R/(P+R)`` or ``2*tp/(2*tp+fp+fn)``.  The F1 or</span>
<span class="sd">        Dice score depends on a TP-only numerator, similarly to the Jaccard</span>
<span class="sd">        index.  For regions where there are no annotations, the F1-score will</span>
<span class="sd">        always be zero, irrespective of the model output.  Accuracy may be a</span>
<span class="sd">        better proxy if one needs to consider the true abscence of annotations</span>
<span class="sd">        in a region as part of the measure.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="p">(</span>
        <span class="n">beta</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">coverage</span><span class="p">),</span>  <span class="c1"># precision</span>
        <span class="n">beta</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">coverage</span><span class="p">),</span>  <span class="c1"># recall</span>
        <span class="n">beta</span><span class="p">(</span><span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">coverage</span><span class="p">),</span>  <span class="c1"># specificity</span>
        <span class="n">beta</span><span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fp</span> <span class="o">+</span> <span class="n">fn</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">coverage</span><span class="p">),</span>  <span class="c1"># accuracy</span>
        <span class="n">beta</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span> <span class="o">+</span> <span class="n">fn</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">coverage</span><span class="p">),</span>  <span class="c1"># jaccard index</span>
        <span class="n">f1_score</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">coverage</span><span class="p">,</span> <span class="mi">100000</span><span class="p">),</span>  <span class="c1"># f1-score</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="compare_systems"><a class="viewcode-back" href="../../../api/bob.measure.credible_region.html#bob.measure.credible_region.compare_systems">[docs]</a><span class="k">def</span> <span class="nf">compare_systems</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">nb_samples</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compares 2 system (binary) outputs using a Dirichlet posterior</span>

<span class="sd">    This function returns the empyrical probability that a system (1) is better</span>
<span class="sd">    another system (2), based on their binary outputs.  The comparison is</span>
<span class="sd">    carried-out as described in [GOUTTE-2005]_, equations 16 and 19, via a</span>
<span class="sd">    Monte-Carlo simulation, since the integral of the probability cannot be</span>
<span class="sd">    resolved analytically.</span>

<span class="sd">    To do so, we compute the probability that :math:`P(\\pi_1 &gt; \\pi_2)`, i.e.,</span>
<span class="sd">    the probability that system 1 gives the expected output while system 2 does</span>
<span class="sd">    not, is greater than the probability that system 1 is incorrect while</span>
<span class="sd">    system 2 gives the correct answer.  It assumes, therefore, systems 1 and 2</span>
<span class="sd">    are tuned (thresholded), and provide binary outputs that can be compared to</span>
<span class="sd">    generate 3 numbers:</span>

<span class="sd">    * :math:`n_1`: The measured number of times system 1 provides the correct</span>
<span class="sd">      answer, whereas system 2 does not</span>
<span class="sd">    * :math:`n_2`: The measured number of times system 2 provides the correct</span>
<span class="sd">      answer, whereas system 1 does not</span>
<span class="sd">    * :math:`n_3`: The measured number of times system 1 and 2 agree, giving</span>
<span class="sd">      the same answer (wrong or write, it does not matter)</span>

<span class="sd">    Notice that :math:`\\pi_1 = \\frac{n_1}{n_1 + n_2 + n_3}`, and so,</span>
<span class="sd">    analogously, you may calculate :math:`\\pi_2` and :math:`\\pi_3`.</span>

<span class="sd">    We then plug these numbers to simulate a Dirichlet (generalisation of the</span>
<span class="sd">    Beta distribution for multiple variables) by setting:</span>

<span class="sd">    * :math:`\\alpha_1 = n_1 + \\lambda_1`</span>
<span class="sd">    * :math:`\\alpha_2 = n_2 + \\lambda_2`</span>
<span class="sd">    * :math:`\\alpha_3 = n_2 + \\lambda_3`</span>

<span class="sd">    Where each :math:`\\lambda_i` correspond to the prior to be imputed to that</span>
<span class="sd">    particular variable.  We typically select :math:`\\lambda_1 = \\lambda_2`,</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    n : tuple</span>
<span class="sd">        A triple with 3 integers representing :math:`n_1`, :math:`n_2` and</span>
<span class="sd">        :math:`n_3`.</span>

<span class="sd">    lambda_ : tuple</span>
<span class="sd">        A tuple with length 3, containing floating point numbers describing the</span>
<span class="sd">        parameterisation of the Dirichlet priors to consider.  Use</span>
<span class="sd">        :math:`\\lambda_i=0.5` for Jeffrey&#39;s prior.</span>

<span class="sd">    nb_samples : int</span>
<span class="sd">        number of generated dirichlet distribution values (make this high, for</span>
<span class="sd">        a higher precision on the simulation).</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>

<span class="sd">    prob : float</span>
<span class="sd">        A number between 0.0 and 1.0 that describes the probability that the</span>
<span class="sd">        first system is better than the second one</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">lambda_</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">dirichlet</span><span class="p">(</span>
        <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">+</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">lambda_</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="n">nb_samples</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">samples</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">samples</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="n">nb_samples</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Idiap Research Institute.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>