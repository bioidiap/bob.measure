<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>bob.measure.binary &mdash; bob.measure 4.2.4b0 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/plot_directive.css" type="text/css" />
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> bob.measure
            <img src="../../../_static/logo.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                4.2.4b0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../guide.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ci.html">Credible and Confidence Intervals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cli.html">Command-Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../references.html">References</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">bob.measure</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../index.html">Module code</a> &raquo;</li>
      <li>bob.measure.binary</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for bob.measure.binary</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python</span>
<span class="c1"># coding=utf-8</span>

<span class="sd">&quot;&quot;&quot;Basic functions for binary classification performance measurement.</span>

<span class="sd">This module contains functions for elementary performance measurement of</span>
<span class="sd">**binary classifiers**.  Most of the functions rely on the input of system</span>
<span class="sd">output scores for both target (a.k.a.  positives) and non-target (a.k.a.</span>
<span class="sd">negatives) samples or integer counts (resulted from pre-thresholding output</span>
<span class="sd">scores).</span>

<span class="sd">We consider ``positives`` scores those originating from samples that are</span>
<span class="sd">labelled to belong to the class of interest (a.k.a., &quot;signal&quot; or &quot;client&quot;).</span>
<span class="sd">``negatives`` scores represent system output for input samples that are labeled</span>
<span class="sd">**not** to belong to the class of interest (a.k.a., &quot;noise&quot; or &quot;impostor&quot;).  It</span>
<span class="sd">is expected that &quot;positive&quot; scores are, at least by design and considering the</span>
<span class="sd">intrinsic score scale, typically greater than &quot;negative&quot; scores in a</span>
<span class="sd">well-designed classifier.</span>

<span class="sd">Every &quot;positive&quot; value that falls bellow the threshold is considered a</span>
<span class="sd">false-negative (FN) or a false-rejection (FR).  Analogously, &quot;negative&quot; samples</span>
<span class="sd">for which the output score of the system falls above the threshold are</span>
<span class="sd">considered a false-positive (FP) or false-acceptance (FA).  Positive scores</span>
<span class="sd">that fall on the threshold (exactly) are considered correctly classified</span>
<span class="sd">(a.k.a. &quot;true positives&quot;).  Negatives that fall on the threshold (exactly) are</span>
<span class="sd">considered **incorrectly** classified (a.k.a. &quot;false positives&quot;).</span>

<span class="sd">The &quot;threshold&quot; use to further classify positive and negative scores into true</span>
<span class="sd">and false variants does not necessarily have to fall within the range covered</span>
<span class="sd">by these scores (negatives and positives altogether).</span>

<span class="sd">In practical situations, it is possible that scores are inverted in the</span>
<span class="sd">negative/positive sense.  For example, in some setups the designer may have</span>
<span class="sd">setup the system so &quot;positive&quot; samples have a smaller score than the &quot;negative&quot;</span>
<span class="sd">ones. In this case, make sure you normalize the scores so positive samples have</span>
<span class="sd">greater scores before feeding them into these methods, e.g., by multiplying all</span>
<span class="sd">scores by -1.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">numbers</span>
<span class="kn">import</span> <span class="nn">numpy</span>


<div class="viewcode-block" id="true_negatives"><a class="viewcode-back" href="../../../api/bob.measure.binary.html#bob.measure.binary.true_negatives">[docs]</a><span class="k">def</span> <span class="nf">true_negatives</span><span class="p">(</span><span class="n">negatives</span><span class="p">,</span> <span class="n">threshold</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Evaluates correctly classifed negatives in a set, based on a threshold</span>

<span class="sd">    This method returns an array composed of booleans that pin-point, which</span>
<span class="sd">    negatives where correctly classified for the given threshold</span>


<span class="sd">    Parameters</span>
<span class="sd">    ==========</span>

<span class="sd">    negatives : numpy.ndarray (1D, float)</span>

<span class="sd">        The scores for non-target objects, or generated by comparing objects of</span>
<span class="sd">        different classes</span>

<span class="sd">    threshold : float</span>

<span class="sd">        The threshold, for which scores should be considered to be correctly</span>
<span class="sd">        classified.  The threshold cannot be ``NaN`` (not-a-number).</span>


<span class="sd">    Returns</span>
<span class="sd">    =======</span>

<span class="sd">    classified : numpy.ndarray (1D, bool)</span>

<span class="sd">        The decision for each of the ``negatives``</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">numpy</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">threshold</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">negatives</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">threshold</span></div>


<span class="n">correctly_classified_negatives</span> <span class="o">=</span> <span class="n">true_negatives</span>


<div class="viewcode-block" id="false_positives"><a class="viewcode-back" href="../../../api/bob.measure.binary.html#bob.measure.binary.false_positives">[docs]</a><span class="k">def</span> <span class="nf">false_positives</span><span class="p">(</span><span class="n">negatives</span><span class="p">,</span> <span class="n">threshold</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Evaluates incorrectly classifed negatives in a set, based on a threshold</span>

<span class="sd">    This method returns an array composed of booleans that pin-point, which</span>
<span class="sd">    negatives where incorrectly classified as positives for the given</span>
<span class="sd">    threshold.</span>


<span class="sd">    Parameters</span>
<span class="sd">    ==========</span>

<span class="sd">    negatives : numpy.ndarray (1D, float)</span>

<span class="sd">        The scores for target objects, or generated by comparing objects of</span>
<span class="sd">        different classes.</span>

<span class="sd">    threshold : float</span>

<span class="sd">        The threshold, for which scores should be considered to be correctly</span>
<span class="sd">        classified.  Cannot be ``NaN`` (not-a-number).</span>


<span class="sd">    Returns</span>
<span class="sd">    =======</span>

<span class="sd">    classified : numpy.ndarray (1D, bool)</span>

<span class="sd">        The decision for each of the ``negative``</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">numpy</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">threshold</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">true_positives</span><span class="p">(</span><span class="n">negatives</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)</span></div>


<div class="viewcode-block" id="true_positives"><a class="viewcode-back" href="../../../api/bob.measure.binary.html#bob.measure.binary.true_positives">[docs]</a><span class="k">def</span> <span class="nf">true_positives</span><span class="p">(</span><span class="n">positives</span><span class="p">,</span> <span class="n">threshold</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Evaluates correctly classifed positives in a set, based on a threshold</span>

<span class="sd">    This method returns an array composed of booleans that pin-point, which</span>
<span class="sd">    positives where correctly classified for the given threshold.</span>

<span class="sd">    The pseudo-code for this function is:</span>


<span class="sd">    Parameters</span>
<span class="sd">    ==========</span>

<span class="sd">    positives : numpy.ndarray (1D, float)</span>

<span class="sd">        The scores for target objects, or generated by comparing objects of</span>
<span class="sd">        the same classe</span>

<span class="sd">    threshold : float</span>

<span class="sd">        The threshold, for which scores should be considered to be correctly</span>
<span class="sd">        classified.  The threshold cannot be ``NaN`` (not-a-number).</span>


<span class="sd">    Returns</span>
<span class="sd">    =======</span>

<span class="sd">    classified : numpy.ndarray (1D, bool)</span>

<span class="sd">        The decision for each of the ``positives``</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">numpy</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">threshold</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">positives</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">threshold</span></div>


<span class="n">correctly_classified_positives</span> <span class="o">=</span> <span class="n">true_positives</span>


<div class="viewcode-block" id="false_negatives"><a class="viewcode-back" href="../../../api/bob.measure.binary.html#bob.measure.binary.false_negatives">[docs]</a><span class="k">def</span> <span class="nf">false_negatives</span><span class="p">(</span><span class="n">positives</span><span class="p">,</span> <span class="n">threshold</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Evaluates incorrectly classifed positives in a set, based on a threshold</span>

<span class="sd">    This method returns an array composed of booleans that pin-point, which</span>
<span class="sd">    positives where incorrectly classified for the given threshold</span>

<span class="sd">    The pseudo-code for this function is:</span>


<span class="sd">    Parameters</span>
<span class="sd">    ==========</span>

<span class="sd">    positives : numpy.ndarray (1D, float)</span>

<span class="sd">        The scores for target objects, or generated by comparing objects of</span>
<span class="sd">        the same class</span>

<span class="sd">    threshold : float</span>

<span class="sd">        The threshold, for which scores should be considered to be correctly</span>
<span class="sd">        classified.  The threshold cannot be ``NaN`` (not-a-number).</span>


<span class="sd">    Returns</span>
<span class="sd">    =======</span>

<span class="sd">    classified : numpy.ndarray (1D, bool)</span>

<span class="sd">        The decision (if incorrectly classified) for each of the ``positives``.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">numpy</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">threshold</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">true_negatives</span><span class="p">(</span><span class="n">positives</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_tricky_division</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Divides n by d.  Returns 0.0 in case of a division by zero&quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">n</span> <span class="o">/</span> <span class="p">(</span><span class="n">d</span> <span class="o">+</span> <span class="p">(</span><span class="n">d</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">_rate_from_ints</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Intermediate function to calculate rates&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">_tricky_division</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="c1"># Sequence[float], float, function</span>
    <span class="k">return</span> <span class="n">_tricky_division</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">](</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>


<div class="viewcode-block" id="true_negative_rate"><a class="viewcode-back" href="../../../api/bob.measure.binary.html#bob.measure.binary.true_negative_rate">[docs]</a><span class="k">def</span> <span class="nf">true_negative_rate</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The true-negative or rejection rate, specificity, or selectivity</span>

<span class="sd">    By definition, the true-negative rate, specificity, or selectivity is the</span>
<span class="sd">    ratio between the number of true negatives and the total number of</span>
<span class="sd">    negatives.  If the number of negative scores is zero, this function</span>
<span class="sd">    exceptionally returns 0.0 instead of ``NaN``.</span>

<span class="sd">    This function accepts 2 signatures:</span>

<span class="sd">    * ``true_negative_rate(tn: int, ttn: int) -&gt; float``</span>
<span class="sd">    * ``true_negative_rate(negatives: Sequence[float], threshold: float) -&gt; float``</span>


<span class="sd">    Parameters</span>
<span class="sd">    ==========</span>

<span class="sd">    tn, ttn: int</span>

<span class="sd">        The number of :py:func:`true_negatives` and total negatives,</span>
<span class="sd">        pre-calculated.</span>

<span class="sd">    negatives : numpy.ndarray (1D, float)</span>

<span class="sd">        The scores for target objects, or generated by comparing objects of</span>
<span class="sd">        different classes</span>

<span class="sd">    threshold : float</span>

<span class="sd">        The threshold to separate correctly and incorrectly classified scores.</span>
<span class="sd">        Cannot be ``NaN`` (not-a-number).</span>


<span class="sd">    Returns</span>
<span class="sd">    =======</span>

<span class="sd">    tnr : float</span>

<span class="sd">        The True Negative Rate (tnr) for the given threshold</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># return tn / ttn</span>
    <span class="k">return</span> <span class="n">_rate_from_ints</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">true_negatives</span><span class="p">)</span></div>


<span class="n">specificity</span> <span class="o">=</span> <span class="n">true_negative_rate</span>
<span class="n">selectivity</span> <span class="o">=</span> <span class="n">true_negative_rate</span>
<span class="n">true_rejection_rate</span> <span class="o">=</span> <span class="n">true_negative_rate</span>


<div class="viewcode-block" id="false_positive_rate"><a class="viewcode-back" href="../../../api/bob.measure.binary.html#bob.measure.binary.false_positive_rate">[docs]</a><span class="k">def</span> <span class="nf">false_positive_rate</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The false-positive or acceptance rate, or fall-out</span>

<span class="sd">    By definition, the false-positive rate or fall-out is the ratio between the</span>
<span class="sd">    number of false positives and the total number of negatives.  If the number</span>
<span class="sd">    of negative scores is zero, this function exceptionally returns 0.0 instead</span>
<span class="sd">    of ``NaN``.</span>

<span class="sd">    This function accepts 2 signatures:</span>

<span class="sd">    * ``false_positive_rate(fp: int, ttn: int) -&gt; float``</span>
<span class="sd">    * ``false_positive_rate(negatives: Sequence[float], threshold: float) -&gt; float``</span>


<span class="sd">    Parameters</span>
<span class="sd">    ==========</span>

<span class="sd">    fp, ttn: int</span>

<span class="sd">        The number of :py:func:`false_positives` and total negatives,</span>
<span class="sd">        pre-calculated.</span>

<span class="sd">    negatives : numpy.ndarray (1D, float)</span>

<span class="sd">        The scores for non-target objects, or generated by comparing objects of</span>
<span class="sd">        different classes</span>

<span class="sd">    threshold : float</span>

<span class="sd">        The threshold to separate correctly and incorrectly classified scores.</span>
<span class="sd">        Cannot be ``NaN`` (not-a-number).</span>


<span class="sd">    Returns</span>
<span class="sd">    =======</span>

<span class="sd">    fpr : float</span>

<span class="sd">        The False Positve Rate (FPR) for the given threshold.  If the number of</span>
<span class="sd">        negative scores is zero, this function exceptionally returns 0.0</span>
<span class="sd">        instead of ``NaN``.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># return fp / ttn</span>
    <span class="k">return</span> <span class="n">_rate_from_ints</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">false_positives</span><span class="p">)</span></div>


<span class="n">fall_out</span> <span class="o">=</span> <span class="n">false_positive_rate</span>
<span class="n">false_acceptance_rate</span> <span class="o">=</span> <span class="n">false_positive_rate</span>


<div class="viewcode-block" id="true_positive_rate"><a class="viewcode-back" href="../../../api/bob.measure.binary.html#bob.measure.binary.true_positive_rate">[docs]</a><span class="k">def</span> <span class="nf">true_positive_rate</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The true-positive or acceptance rate, sensitivity, recall or hit rate</span>

<span class="sd">    By definition, the true-positive rate, sensitivity, recall or hit-rate is</span>
<span class="sd">    the ratio between the number of true positives and the total number of</span>
<span class="sd">    positives.  If the number of positives is zero, this function exceptionally</span>
<span class="sd">    returns 0.0 instead of ``NaN``.</span>

<span class="sd">    This function accepts 2 signatures:</span>

<span class="sd">    * ``true_positive_rate(tp: int, ttp: int) -&gt; float``</span>
<span class="sd">    * ``true_positive_rate(positives: Sequence[float], threshold: float) -&gt; float``</span>


<span class="sd">    Parameters</span>
<span class="sd">    ==========</span>

<span class="sd">    tp, ttp: int</span>

<span class="sd">        The number of :py:func:`true_positives` and total number of positive</span>
<span class="sd">        scores, pre-calculated.</span>

<span class="sd">    positives : numpy.ndarray (1D, float)</span>

<span class="sd">        The scores for target objects, or generated by comparing objects of</span>
<span class="sd">        the same class</span>

<span class="sd">    threshold : float</span>

<span class="sd">        The threshold to separate correctly and incorrectly classified scores.</span>
<span class="sd">        Cannot be ``NaN`` (not-a-number).</span>


<span class="sd">    Returns</span>
<span class="sd">    =======</span>

<span class="sd">    tpr : float</span>

<span class="sd">        The True Positive Rate (tpr) for the given threshold.  If the number of</span>
<span class="sd">        positives is zero, this function exceptionally returns 0.0 instead of</span>
<span class="sd">        ``NaN``.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># return tp / ttp</span>
    <span class="k">return</span> <span class="n">_rate_from_ints</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">true_positives</span><span class="p">)</span></div>


<span class="n">sensitivity</span> <span class="o">=</span> <span class="n">true_positive_rate</span>
<span class="n">recall</span> <span class="o">=</span> <span class="n">true_positive_rate</span>
<span class="n">hit_rate</span> <span class="o">=</span> <span class="n">true_positive_rate</span>
<span class="n">true_acceptance_rate</span> <span class="o">=</span> <span class="n">true_positive_rate</span>


<div class="viewcode-block" id="false_negative_rate"><a class="viewcode-back" href="../../../api/bob.measure.binary.html#bob.measure.binary.false_negative_rate">[docs]</a><span class="k">def</span> <span class="nf">false_negative_rate</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The false-negative or rejection rate or miss-rate</span>

<span class="sd">    By definition, the false-negative rate or miss-rate is the ratio between</span>
<span class="sd">    the number of false negatives and the total number of positives. If the</span>
<span class="sd">    number of positives is zero, this function exceptionally returns 0.0</span>
<span class="sd">    instead of ``NaN``.</span>

<span class="sd">    This function accepts 2 signatures:</span>

<span class="sd">    * ``false_negative_rate(fn: int, ttp: int) -&gt; float``</span>
<span class="sd">    * ``false_negative_rate(positives: Sequence[float], threshold: float) -&gt; float``</span>


<span class="sd">    Parameters</span>
<span class="sd">    ==========</span>

<span class="sd">    fn, ttp: int</span>

<span class="sd">        The number of :py:func:`false_negatives` and total positives,</span>
<span class="sd">        pre-calculated.</span>

<span class="sd">    positives : numpy.ndarray (1D, float)</span>

<span class="sd">        The scores for target objects, or generated by comparing objects of</span>
<span class="sd">        the same class</span>

<span class="sd">    threshold : float</span>

<span class="sd">        The threshold to separate correctly and incorrectly classified scores.</span>
<span class="sd">        The threshold cannot be ``NaN`` (not-a-number).</span>


<span class="sd">    Returns</span>
<span class="sd">    =======</span>

<span class="sd">    fnr : float</span>

<span class="sd">        The False Negative Rate (FPR) for the given threshold.  If the number</span>
<span class="sd">        of positives is zero, this function exceptionally returns 0.0 instead</span>
<span class="sd">        of ``NaN``.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># return fn / ttp</span>
    <span class="k">return</span> <span class="n">_rate_from_ints</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">false_negatives</span><span class="p">)</span></div>


<span class="n">miss_rate</span> <span class="o">=</span> <span class="n">false_negative_rate</span>
<span class="n">false_rejection_rate</span> <span class="o">=</span> <span class="n">false_negative_rate</span>


<div class="viewcode-block" id="precision"><a class="viewcode-back" href="../../../api/bob.measure.binary.html#bob.measure.binary.precision">[docs]</a><span class="k">def</span> <span class="nf">precision</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Calculates the precision or positive-predictive value (PPV)</span>

<span class="sd">    The precision or positive predictive value (PPV) is defined by:</span>

<span class="sd">    .. math::</span>

<span class="sd">       \\mathrm{ppv} = \\frac{tp}{tp + fp}</span>

<span class="sd">    Notice that, in the case ``tp+fp == 0``, this function returns 0.0,</span>
<span class="sd">    exceptionally.  TP and FP may be calculated from both ``negative`` and</span>
<span class="sd">    ``positive`` scores if a threshold is also provided.  This function has two</span>
<span class="sd">    signatures:</span>

<span class="sd">    * ``precision(fp: int, tp: int) -&gt; float``</span>
<span class="sd">    * ``precision(negatives: Sequence[float], positives: Sequence[float], threshold: float) -&gt; float``</span>


<span class="sd">    Parameters</span>
<span class="sd">    ==========</span>

<span class="sd">    fp, tp : int</span>

<span class="sd">        The number of :py:func:`false_positives` and :py:func:`true_positives`,</span>
<span class="sd">        pre-calculated.</span>

<span class="sd">    negatives, positives : numpy.ndarray (1D, float)</span>

<span class="sd">        The set of negative and positive scores to compute the measurement</span>

<span class="sd">    threshold : float</span>

<span class="sd">        The threshold to compute the measures for.  Cannot be ``NaN``.  Only</span>
<span class="sd">        useful if arrays of ``negatives`` and ``positives`` are provided.</span>


<span class="sd">    Returns</span>
<span class="sd">    =======</span>

<span class="sd">    precision : float</span>

<span class="sd">        The precision.  Notice that, in the case ``tn+fn == 0``, this function</span>
<span class="sd">        returns 0.0, exceptionally.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
        <span class="c1"># return tp / (fp + tp)</span>
        <span class="k">return</span> <span class="n">_tricky_division</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">precision</span><span class="p">(</span>
        <span class="n">false_positives</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>  <span class="c1"># fp</span>
        <span class="n">true_positives</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>  <span class="c1"># tp</span>
    <span class="p">)</span></div>


<span class="n">positive_predictive_value</span> <span class="o">=</span> <span class="n">precision</span>


<div class="viewcode-block" id="negative_predictive_value"><a class="viewcode-back" href="../../../api/bob.measure.binary.html#bob.measure.binary.negative_predictive_value">[docs]</a><span class="k">def</span> <span class="nf">negative_predictive_value</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Calculates the negative-predictive value (NPV)</span>

<span class="sd">    The negative predictive value (NPV) is defined by:</span>

<span class="sd">    .. math::</span>

<span class="sd">       \mathrm{npv} = \frac{tn}{tn + fn}</span>

<span class="sd">    Notice that, in the case ``tn+fn == 0``, this function returns 0.0,</span>
<span class="sd">    exceptionally.  TP and FP may be calculated from both ``negative`` and</span>
<span class="sd">    ``positive`` scores if a threshold is also provided.  This function has two</span>
<span class="sd">    signatures:</span>

<span class="sd">    * ``negative_predictive_value(tn: int, fn: int) -&gt; float``</span>
<span class="sd">    * ``negative_predictive_value(negatives: Sequence[float], positives: Sequence[float], threshold: float) -&gt; float``</span>


<span class="sd">    Parameters</span>
<span class="sd">    ==========</span>

<span class="sd">    tn, fn : int</span>

<span class="sd">        The number of :py:func:`true_negatives` and :py:func:`false_negatives`,</span>
<span class="sd">        pre-calculated.</span>

<span class="sd">    negatives, positives : numpy.ndarray (1D, float)</span>

<span class="sd">        The set of negative and positive scores to compute the measurement</span>

<span class="sd">    threshold : float</span>

<span class="sd">        The threshold to compute the measures for.  Cannot be ``NaN``.  Only</span>
<span class="sd">        useful if arrays of ``negatives`` and ``positives`` are provided.</span>


<span class="sd">    Returns</span>
<span class="sd">    =======</span>

<span class="sd">    npv : float</span>

<span class="sd">        The negative-predictive value for the given negatives and positives, at</span>
<span class="sd">        a given threshold.  Notice that, in the case ``tn+fn == 0``, this</span>
<span class="sd">        function returns 0.0, exceptionally.</span>


<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
        <span class="c1"># return tn / (tn + fn)</span>
        <span class="k">return</span> <span class="n">_tricky_division</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">negative_predictive_value</span><span class="p">(</span>
        <span class="n">true_negatives</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>  <span class="c1"># tn</span>
        <span class="n">false_negatives</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>  <span class="c1"># fn</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="precision_recall"><a class="viewcode-back" href="../../../api/bob.measure.binary.html#bob.measure.binary.precision_recall">[docs]</a><span class="k">def</span> <span class="nf">precision_recall</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Handle to calculate precision and recall in a single call.</span>

<span class="sd">    See:</span>

<span class="sd">    * :py:func:`precision`</span>
<span class="sd">    * :py:func:`recall`</span>

<span class="sd">    This function has two signatures:</span>

<span class="sd">    * ``precision_recall(fp: int, tp: int, ttp: int) -&gt; (float, float)``</span>
<span class="sd">    * ``precision_recall(negatives: Sequence[float], positives: Sequence[float], threshold: float) -&gt; (float, float)``</span>


<span class="sd">    Parameters</span>
<span class="sd">    ==========</span>

<span class="sd">    fp, tp, ttp: int</span>

<span class="sd">        The number of :py:func:`false_positives`, :py:func:`true_positives`,</span>
<span class="sd">        and total number of positive scores, pre-calculated.</span>

<span class="sd">    negatives, positives : numpy.ndarray (1D, float)</span>

<span class="sd">        The set of negative and positive scores to compute the measurements</span>

<span class="sd">    threshold : float</span>

<span class="sd">        The threshold to compute the measures for</span>


<span class="sd">    Returns</span>
<span class="sd">    =======</span>

<span class="sd">    precision : float</span>

<span class="sd">        The precision value for the given negatives and positives</span>

<span class="sd">    recall : float</span>

<span class="sd">        The recall value for the given negatives and positives</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">precision</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">recall</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;negatives or positives should not be empty&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">precision_recall</span><span class="p">(</span>
        <span class="n">false_positives</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>  <span class="c1"># fp</span>
        <span class="n">true_positives</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>  <span class="c1"># tp</span>
        <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>  <span class="c1"># ttp</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="fprfnr"><a class="viewcode-back" href="../../../api/bob.measure.binary.html#bob.measure.binary.fprfnr">[docs]</a><span class="k">def</span> <span class="nf">fprfnr</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Helper to calculate both the FPR (FAR) and FNR (FRR) in one go</span>

<span class="sd">    See:</span>

<span class="sd">    * :py:func:`false_positive_rate`</span>
<span class="sd">    * :py:func:`false_negative_rate`</span>


<span class="sd">    This function has two signatures:</span>

<span class="sd">    * ``fprfnr(fp: int, ttn: int, fn: int, ttp: int) -&gt; (float, float)``</span>
<span class="sd">    * ``fprfnr(negatives: Sequence[float], positives: Sequence[float], threshold: float) -&gt; (float, float)``</span>


<span class="sd">    Parameters</span>
<span class="sd">    ==========</span>

<span class="sd">    fp, ttn, fn, ttp: int</span>

<span class="sd">        The number of :py:func:`false_positives`, total negatives,</span>
<span class="sd">        :py:func:`false_negatives`, and total positives, pre-calculated.</span>

<span class="sd">    negatives, positives : numpy.ndarray (1D, float)</span>

<span class="sd">        The scores for non-target and target samples</span>

<span class="sd">    threshold : float</span>

<span class="sd">        The threshold to separate correctly and incorrectly classified scores</span>


<span class="sd">    Returns</span>
<span class="sd">    =======</span>

<span class="sd">    fpr : float</span>

<span class="sd">        The False Positve Rate (FPR) or False Acceptance Rate (FAR) for the</span>
<span class="sd">        given threshold</span>

<span class="sd">    fnr : float</span>

<span class="sd">        The False Negative Rate (FNR) or False Reject Rate (FRR) for the given</span>
<span class="sd">        threshold</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
        <span class="c1"># return fp / ttn, fn / ttp</span>
        <span class="k">return</span> <span class="n">false_positive_rate</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">false_negative_rate</span><span class="p">(</span>
            <span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;negatives or positives should not be empty&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fprfnr</span><span class="p">(</span>
        <span class="n">false_positives</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>  <span class="c1"># fp</span>
        <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>  <span class="c1"># ttn</span>
        <span class="n">false_negatives</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>  <span class="c1"># fn</span>
        <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>  <span class="c1"># ttp</span>
    <span class="p">)</span></div>


<span class="n">farfrr</span> <span class="o">=</span> <span class="n">fprfnr</span>


<div class="viewcode-block" id="f1_score"><a class="viewcode-back" href="../../../api/bob.measure.binary.html#bob.measure.binary.f1_score">[docs]</a><span class="k">def</span> <span class="nf">f1_score</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the F-score of the accuracy of the classification</span>

<span class="sd">    The F-score is a weighted mean of precision and recall measurements, see</span>
<span class="sd">    :py:func:`precision_recall`.  It is computed as:</span>

<span class="sd">    .. math::</span>

<span class="sd">       \mathrm{\text{f-score}}(w) = (1 + w^2)\frac{\mathrm{precision}\cdot{}\mathrm{recall}}{w^2\cdot{}\mathrm{precision} + \mathrm{recall}}</span>

<span class="sd">    The weight :math:`w` needs to be non-negative real value. In case the</span>
<span class="sd">    weight parameter is 1 (current implementation), the F-score is called F1</span>
<span class="sd">    score and represents the harmonic mean between precision and recall values.</span>
<span class="sd">    This function exceptionally returns ``0.0`` if the denominator above is</span>
<span class="sd">    zero.</span>

<span class="sd">    This function has two signatures:</span>

<span class="sd">    * ``f1_score(fp: int, tp: int, ttn: int) -&gt; float``</span>
<span class="sd">    * ``f1_score(negatives: Sequence[float], positives: Sequence[float], threshold: float) -&gt; float``</span>


<span class="sd">    Parameters</span>
<span class="sd">    ==========</span>

<span class="sd">    fp, tp, ttn: int</span>

<span class="sd">        The number of :py:func:`false_positives`, :py:func:`true_positives`,</span>
<span class="sd">        and total negatives, pre-calculated.</span>

<span class="sd">    negatives, positives : numpy.ndarray (1D, float)</span>

<span class="sd">        The scores for non-target and target samples</span>

<span class="sd">    threshold : float</span>

<span class="sd">        The threshold to compute the f1-score for.  Cannot be ``NaN``</span>
<span class="sd">        (not-a-number).</span>


<span class="sd">    Returns</span>
<span class="sd">    =======</span>

<span class="sd">    f1_score : float</span>

<span class="sd">        The computed F1-score</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span><span class="p">,</span> <span class="n">r</span> <span class="o">=</span> <span class="n">precision_recall</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">_tricky_division</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">p</span> <span class="o">*</span> <span class="n">r</span><span class="p">),</span> <span class="p">(</span><span class="n">p</span> <span class="o">+</span> <span class="n">r</span><span class="p">))</span></div>


<div class="viewcode-block" id="accuracy"><a class="viewcode-back" href="../../../api/bob.measure.binary.html#bob.measure.binary.accuracy">[docs]</a><span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the the accuracy of classification</span>

<span class="sd">    Accuracy is the proportion of correct predictions (both true positives and</span>
<span class="sd">    true negatives) among the total number of elements examined.  It</span>
<span class="sd">    corresponds arithmetically to:</span>

<span class="sd">    .. math::</span>
<span class="sd">       :nowrap:</span>

<span class="sd">       \begin{align*}</span>
<span class="sd">           \mathrm{Acc} &amp;= \frac{\mathrm{tn}+\mathrm{tp}}{\mathrm{tn}+\mathrm{fp}+\mathrm{tp}+\mathrm{fn}} \\</span>
<span class="sd">           \mathrm{Acc} &amp;= \frac{\mathrm{tn}+\mathrm{tp}}{\mathrm{ttn}+\mathrm{ttp}}</span>
<span class="sd">       \end{align*}</span>

<span class="sd">    In the special case where ``ttn+ttp == 0``, this function returns zero for</span>
<span class="sd">    accuracy.</span>

<span class="sd">    Because it considers both TP and TN in the numerator, this measure is</span>
<span class="sd">    sensitive to threshold domains which may be completely dominated by true</span>
<span class="sd">    positive or negative scores.</span>

<span class="sd">    This function has two signatures:</span>

<span class="sd">    * ``accuracy(tn: int, ttn: int, tp: int, ttp: int) -&gt; float``</span>
<span class="sd">    * ``accuracy(negatives: Sequence[float], positives: Sequence[float], threshold: float) -&gt; float``</span>


<span class="sd">    Parameters</span>
<span class="sd">    ==========</span>

<span class="sd">    tn, ttn, tp, ttp: int</span>

<span class="sd">        The number of :py:func:`true_negatives`, total negatives,</span>
<span class="sd">        :py:func:`true_positives`, total positives, pre-calculated.</span>

<span class="sd">    negatives, positives : numpy.ndarray (1D, float)</span>

<span class="sd">        The scores for non-target and target samples</span>

<span class="sd">    threshold : float</span>

<span class="sd">        The threshold to compute the accuracy for.  Cannot be ``NaN``</span>
<span class="sd">        (not-a-number).</span>


<span class="sd">    Returns</span>
<span class="sd">    =======</span>

<span class="sd">    acc : float</span>

<span class="sd">        The computed accuracy</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
        <span class="c1"># (tn+tp)/(ttn+ttp)</span>
        <span class="k">return</span> <span class="n">tricky_division</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">args</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">accuracy</span><span class="p">(</span>
        <span class="n">true_negatives</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>  <span class="c1"># tn</span>
        <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>  <span class="c1"># ttn</span>
        <span class="n">true_positives</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>  <span class="c1"># tp</span>
        <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>  <span class="c1"># ttp</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="balanced_accuracy"><a class="viewcode-back" href="../../../api/bob.measure.binary.html#bob.measure.binary.balanced_accuracy">[docs]</a><span class="k">def</span> <span class="nf">balanced_accuracy</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the the balanced accuracy of classification</span>

<span class="sd">    Balance accuracy corresponds arithmetically to:</span>

<span class="sd">    .. math::</span>

<span class="sd">       \mathrm{BA} = \frac{\mathrm{tnr}+\mathrm{tpr}}{2}</span>

<span class="sd">    This function has two signatures:</span>

<span class="sd">    * ``balanced_accuracy(tn: int, ttn: int, tp: int, ttp: int) -&gt; float``</span>
<span class="sd">    * ``balanced_accuracy(negatives: Sequence[float], positives: Sequence[float], threshold: float) -&gt; float``</span>


<span class="sd">    Parameters</span>
<span class="sd">    ==========</span>

<span class="sd">    tn, ttn, tp, ttp: int</span>

<span class="sd">        The number of :py:func:`true_negatives`, total negatives,</span>
<span class="sd">        :py:func:`true_positives`, total positives, pre-calculated.</span>

<span class="sd">    negatives, positives : numpy.ndarray (1D, float)</span>

<span class="sd">        The scores for non-target and target samples</span>

<span class="sd">    threshold : float</span>

<span class="sd">        The threshold to compute the balanced accuracy for.  Cannot be ``NaN``</span>
<span class="sd">        (not-a-number).</span>


<span class="sd">    Returns</span>
<span class="sd">    =======</span>

<span class="sd">    ba : float</span>

<span class="sd">        The computed balanced accuracy</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">true_negative_rate</span><span class="p">(</span><span class="n">tn</span><span class="p">,</span> <span class="n">ttn</span><span class="p">)</span> <span class="o">+</span> <span class="n">true_positive_rate</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">ttp</span><span class="p">))</span> <span class="o">/</span> <span class="mf">2.0</span>
    <span class="k">return</span> <span class="n">balanced_accuracy</span><span class="p">(</span>
        <span class="n">true_negatives</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>  <span class="c1"># tn</span>
        <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>  <span class="c1"># ttn</span>
        <span class="n">true_positives</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>  <span class="c1"># tp</span>
        <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>  <span class="c1"># ttp</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="half_total_error_rate"><a class="viewcode-back" href="../../../api/bob.measure.binary.html#bob.measure.binary.half_total_error_rate">[docs]</a><span class="k">def</span> <span class="nf">half_total_error_rate</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the the half-total error rate (HTER) of classification</span>

<span class="sd">    The HTER corresponds arithmetically to:</span>

<span class="sd">    .. math::</span>
<span class="sd">       :nowrap:</span>

<span class="sd">       \begin{align*}</span>
<span class="sd">           \mathrm{HTER} &amp;= \frac{\mathrm{fpr}+\mathrm{fnr}}{2} \\</span>
<span class="sd">           \mathrm{HTER} &amp;= \frac{(1-\mathrm{tnr})+(1-\mathrm{tpr})}{2} \\</span>
<span class="sd">           \mathrm{HTER} &amp;= 1 - \frac{\mathrm{tnr}+\mathrm{tpr}}{2} \\</span>
<span class="sd">           \mathrm{HTER} &amp;= 1 - BA</span>
<span class="sd">       \end{align*}</span>

<span class="sd">    * See :py:func:`balanced_accuracy`</span>

<span class="sd">    This function has two signatures:</span>

<span class="sd">    * ``half_total_error_rate(tn: int, ttn: int, tp: int, ttp: int) -&gt; float``</span>
<span class="sd">    * ``half_total_error_rate(negatives: Sequence[float], positives: Sequence[float], threshold: float) -&gt; float``</span>


<span class="sd">    Parameters</span>
<span class="sd">    ==========</span>

<span class="sd">    tn, ttn, tp, ttp: int</span>

<span class="sd">        The number of :py:func:`true_negatives`, total negatives,</span>
<span class="sd">        :py:func:`true_positives`, total positives, pre-calculated.</span>

<span class="sd">    negatives, positives : numpy.ndarray (1D, float)</span>

<span class="sd">        The scores for non-target and target samples</span>

<span class="sd">    threshold : float</span>

<span class="sd">        The threshold to compute the half-total error rate for.  Cannot be</span>
<span class="sd">        ``NaN`` (not-a-number).</span>


<span class="sd">    Returns</span>
<span class="sd">    =======</span>

<span class="sd">    hter : float</span>

<span class="sd">        The computed half-total error rate</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">balanced_accuracy</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span></div>


<div class="viewcode-block" id="jaccard_index"><a class="viewcode-back" href="../../../api/bob.measure.binary.html#bob.measure.binary.jaccard_index">[docs]</a><span class="k">def</span> <span class="nf">jaccard_index</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the Jaccard or Similarity index of a classifier</span>

<span class="sd">    The Jaccard-index corresponds arithmetically:</span>

<span class="sd">    .. math::</span>
<span class="sd">       :nowrap:</span>

<span class="sd">       \begin{align*}</span>
<span class="sd">           \mathrm{J} &amp;= \frac{\mathrm{tp}}{\mathrm{fp}+\mathrm{tp}+\mathrm{fn}} \\</span>
<span class="sd">           \mathrm{J} &amp;= \frac{\mathrm{tp}}{\mathrm{fp}+\mathrm{ttp}}</span>
<span class="sd">       \end{align*}</span>

<span class="sd">    In the special case where ``tn+fp+fn == 0``, this function returns zero for</span>
<span class="sd">    the Jaccard index.</span>

<span class="sd">    The Jaccard index depends on a TP-only numerator, similarly to the F1</span>
<span class="sd">    score.  This measure is not sensible to regions of the score domain where</span>
<span class="sd">    no true-positives are available.  The ``accuracy`` may be a better proxy in</span>
<span class="sd">    these cases.</span>

<span class="sd">    This function has two signatures:</span>

<span class="sd">    * ``jaccard_index(fp, tp, ttp)``</span>
<span class="sd">    * ``jaccard_index(negatives, positives, threshold)``</span>


<span class="sd">    Parameters</span>
<span class="sd">    ==========</span>

<span class="sd">    fp, tp, ttp: int</span>

<span class="sd">        The number of :py:func:`false_positives`, :py:func:`true_positives` and</span>
<span class="sd">        total positive scores, pre-calculated.</span>

<span class="sd">    negatives : numpy.ndarray (1D, float)</span>

<span class="sd">        The scores for non-target and target samples</span>

<span class="sd">    threshold : float</span>

<span class="sd">        The threshold to compute the Jaccard index for.  Cannot be ``NaN``</span>
<span class="sd">        (not-a-number).</span>


<span class="sd">    Returns</span>
<span class="sd">    =======</span>

<span class="sd">    jaccard_index : float</span>

<span class="sd">        The computed Jaccard or Similarity index for the given scores and the</span>
<span class="sd">        given threshold</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
        <span class="c1"># tp/(fp+ttp)</span>
        <span class="k">return</span> <span class="n">tricky_division</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">jaccard_index</span><span class="p">(</span>
        <span class="n">false_positives</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>  <span class="c1"># fp</span>
        <span class="n">true_positives</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>  <span class="c1"># tp</span>
        <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>  <span class="c1"># ttp</span>
    <span class="p">)</span></div>


<span class="n">jaccard</span> <span class="o">=</span> <span class="n">jaccard_index</span>
<span class="n">similarly_index</span> <span class="o">=</span> <span class="n">jaccard_index</span>


<div class="viewcode-block" id="matthews_correlation_coefficient"><a class="viewcode-back" href="../../../api/bob.measure.binary.html#bob.measure.binary.matthews_correlation_coefficient">[docs]</a><span class="k">def</span> <span class="nf">matthews_correlation_coefficient</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the Matthews Correlation Coefficient (MCC) or Phi Coefficient of a classifier</span>

<span class="sd">    The MCC corresponds arithmetically:</span>

<span class="sd">    .. math::</span>

<span class="sd">       \mathrm{MCC} = \frac{\mathrm{tp}\mathrm{tn} - \mathrm{fp}\mathrm{fn}}{\sqrt{(\mathrm{tp}+\mathrm{fp})(\mathrm{tp}+\mathrm{fn})(\mathrm{tn}+\mathrm{fp})(\mathrm{tn}+\mathrm{fn})}}</span>

<span class="sd">    In the special case where the denominator is ``0.0``, this function returns</span>
<span class="sd">    zero for the MCC.</span>

<span class="sd">    This function has two signatures:</span>

<span class="sd">    * ``matthews_correlation_coefficient(tn: int, ttn: int, tp: int, ttp: int) -&gt; float``</span>
<span class="sd">    * ``matthews_correlation_coefficient(negatives: Sequence[float], positives: Sequence[float], threshold: Sequence[float]) -&gt; float``</span>


<span class="sd">    Parameters</span>
<span class="sd">    ==========</span>

<span class="sd">    tn, ttn, tp, ttp: int</span>

<span class="sd">        The number of :py:func:`true_negatives`, total negative scores,</span>
<span class="sd">        :py:func:`true_positives` and total positive scores, pre-calculated.</span>

<span class="sd">    negatives, positives : numpy.ndarray (1D, float)</span>

<span class="sd">        The scores for non-target and target samples</span>

<span class="sd">    threshold : float</span>

<span class="sd">        The threshold to compute the MCC for.  Cannot be ``NaN``</span>
<span class="sd">        (not-a-number).</span>


<span class="sd">    Returns</span>
<span class="sd">    =======</span>

<span class="sd">    mcc : float</span>

<span class="sd">        The computed MCC of Phi Coefficient</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
        <span class="c1"># ((tp*tn) - (fp*fn)/sqrt((tp+fp)(tp+fn)(tn+fp)(tn+fn))</span>
        <span class="n">tn</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">fp</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">tp</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">fn</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">-</span> <span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">tricky_division</span><span class="p">(</span>
            <span class="p">(</span><span class="n">tp</span> <span class="o">*</span> <span class="n">tn</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">fp</span> <span class="o">*</span> <span class="n">fn</span><span class="p">),</span>
            <span class="p">((</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fp</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fn</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">tn</span> <span class="o">+</span> <span class="n">fp</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">tn</span> <span class="o">+</span> <span class="n">fn</span><span class="p">))</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">matthews_correlation_coefficient</span><span class="p">(</span>
        <span class="n">true_negatives</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>  <span class="c1"># tn</span>
        <span class="nb">len</span><span class="p">(</span><span class="n">negatives</span><span class="p">),</span>  <span class="c1"># ttn</span>
        <span class="n">true_positives</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>  <span class="c1"># tp</span>
        <span class="nb">len</span><span class="p">(</span><span class="n">positives</span><span class="p">),</span>  <span class="c1"># ttp</span>
    <span class="p">)</span></div>


<span class="n">phi_coefficient</span> <span class="o">=</span> <span class="n">matthews_correlation_coefficient</span>


<div class="viewcode-block" id="measures"><a class="viewcode-back" href="../../../api/bob.measure.binary.html#bob.measure.binary.measures">[docs]</a><span class="k">def</span> <span class="nf">measures</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;In a single call, calculate most of the quantities in this module</span>

<span class="sd">    This function simplifies the calculation of most performance measures in</span>
<span class="sd">    this module through a single call.</span>

<span class="sd">    This function accepts 2 signatures:</span>

<span class="sd">    * ``measures(tn: int, ttn: int, tp: int, ttp: int) -&gt; Sequence[float]``</span>
<span class="sd">    * ``measures(negatives: Sequence[float], positives: Sequence[float], threshold: float) -&gt; Sequence[float]``</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    tn, ttn, tp, ttp: int</span>

<span class="sd">        The number of :py:func:`true_negatives`, total negatives,</span>
<span class="sd">        :py:func:`true_positives`, total positives, pre-calculated.</span>

<span class="sd">    negatives, positives : numpy.ndarray (1D, float)</span>

<span class="sd">        The scores for non-target and target samples</span>

<span class="sd">    threshold : float</span>

<span class="sd">        The threshold to compute the accuracy for.  Cannot be ``NaN``</span>
<span class="sd">        (not-a-number).</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>

<span class="sd">    specificity : float</span>
<span class="sd">        Selectivity or true negative rate, see :py:func:`specificity`</span>

<span class="sd">    recall : float</span>
<span class="sd">        Sensitivity, hit rate, or true positive rate, see :py:func:`recall`</span>

<span class="sd">    precision : float</span>
<span class="sd">        Or Positive-Predictive Value (PPV), see :py:func:`precision`</span>

<span class="sd">    f1_score : float</span>
<span class="sd">        See :py:func:`f1_score`</span>

<span class="sd">    accuracy : float</span>
<span class="sd">        See :py:func:`accuracy`</span>

<span class="sd">    half_total_error_rate : float</span>
<span class="sd">        See :py:func:`half_total_error_rate`</span>

<span class="sd">    jaccard_index : float</span>
<span class="sd">        See :py:func:`jaccard_index`</span>

<span class="sd">    matthews_correlation_coefficient : float</span>
<span class="sd">        See :py:func:`matthews_correlation_coefficient`</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
        <span class="n">tn</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">ttn</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">fp</span> <span class="o">=</span> <span class="n">ttn</span> <span class="o">-</span> <span class="n">tn</span>
        <span class="n">tp</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">ttp</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">specificity</span><span class="p">(</span><span class="n">tn</span><span class="p">,</span> <span class="n">ttn</span><span class="p">),</span>  <span class="c1"># ==true negative rate</span>
            <span class="n">recall</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">ttp</span><span class="p">),</span>  <span class="c1"># == true positive rate</span>
            <span class="n">precision</span><span class="p">(</span><span class="n">fp</span><span class="p">,</span> <span class="n">tp</span><span class="p">),</span>  <span class="c1"># == positive predicitve value</span>
            <span class="n">f1_score</span><span class="p">(</span><span class="n">fp</span><span class="p">,</span> <span class="n">tp</span><span class="p">,</span> <span class="n">ttn</span><span class="p">),</span>
            <span class="n">accuracy</span><span class="p">(</span><span class="n">tn</span><span class="p">,</span> <span class="n">ttn</span><span class="p">,</span> <span class="n">tp</span><span class="p">,</span> <span class="n">ttp</span><span class="p">),</span>
            <span class="n">balanced_accuracy</span><span class="p">(</span><span class="n">tn</span><span class="p">,</span> <span class="n">ttn</span><span class="p">,</span> <span class="n">tp</span><span class="p">,</span> <span class="n">ttp</span><span class="p">),</span>
            <span class="n">half_total_error_rate</span><span class="p">(</span><span class="n">tn</span><span class="p">,</span> <span class="n">ttn</span><span class="p">,</span> <span class="n">tp</span><span class="p">,</span> <span class="n">ttp</span><span class="p">),</span>
            <span class="n">jaccard_index</span><span class="p">(</span><span class="n">fp</span><span class="p">,</span> <span class="n">tp</span><span class="p">,</span> <span class="n">ttp</span><span class="p">),</span>
            <span class="n">matthews_correlation_coefficient</span><span class="p">(</span><span class="n">tn</span><span class="p">,</span> <span class="n">ttn</span><span class="p">,</span> <span class="n">tp</span><span class="p">,</span> <span class="n">ttp</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="n">neg</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">pos</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="k">return</span> <span class="p">(</span>
        <span class="n">specificity</span><span class="p">(</span><span class="n">neg</span><span class="p">,</span> <span class="n">t</span><span class="p">),</span>
        <span class="n">recall</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">t</span><span class="p">),</span>
        <span class="n">precision</span><span class="p">(</span><span class="n">neg</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">t</span><span class="p">),</span>
        <span class="n">f1_score</span><span class="p">(</span><span class="n">neg</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">t</span><span class="p">),</span>
        <span class="n">accuracy</span><span class="p">(</span><span class="n">neg</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">t</span><span class="p">),</span>
        <span class="n">balanced_accuracy</span><span class="p">(</span><span class="n">neg</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">t</span><span class="p">),</span>
        <span class="n">half_total_error_rate</span><span class="p">(</span><span class="n">neg</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">t</span><span class="p">),</span>
        <span class="n">jaccard_index</span><span class="p">(</span><span class="n">neg</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">t</span><span class="p">),</span>
        <span class="n">matthews_correlation_coefficient</span><span class="p">(</span><span class="n">neg</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">t</span><span class="p">),</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="eer"><a class="viewcode-back" href="../../../api/bob.measure.binary.html#bob.measure.binary.eer">[docs]</a><span class="k">def</span> <span class="nf">eer</span><span class="p">(</span><span class="n">negatives</span><span class="p">,</span> <span class="n">positives</span><span class="p">,</span> <span class="n">is_sorted</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">also_farfrr</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculates the Equal Error Rate (EER)</span>

<span class="sd">    Please note that it is possible that eer != fpr != fnr.  This function</span>
<span class="sd">    returns (fpr + fnr) / 2 as eer.  If you also need the fpr and fnr values,</span>
<span class="sd">    set ``also_farfrr`` to ``True``.</span>


<span class="sd">    Parameters</span>
<span class="sd">    ==========</span>

<span class="sd">    negatives, positives : numpy.ndarray (1D, float)</span>
<span class="sd">        The set of negative and positive scores to compute the measurement</span>

<span class="sd">    is_sorted : bool</span>
<span class="sd">        Are both sets of scores already in ascendantly sorted order?</span>

<span class="sd">    also_farfrr : bool</span>
<span class="sd">        If True, it will also return far and frr.</span>


<span class="sd">    Returns</span>
<span class="sd">    =======</span>

<span class="sd">    eer : float</span>
<span class="sd">        The Equal Error Rate (EER).</span>

<span class="sd">    fpr : float</span>
<span class="sd">        The False Positive Rate (FPR). Returned only when ``also_farfrr`` is</span>
<span class="sd">        ``True``.</span>

<span class="sd">    fnr : float</span>
<span class="sd">        The False Negative Rate (FNR). Returned only when ``also_farfrr`` is</span>
<span class="sd">        ``True``.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">brute_force</span> <span class="kn">import</span> <span class="n">eer_threshold</span>

    <span class="n">threshold</span> <span class="o">=</span> <span class="n">eer_threshold</span><span class="p">(</span><span class="n">negatives</span><span class="p">,</span> <span class="n">positives</span><span class="p">,</span> <span class="n">is_sorted</span><span class="p">)</span>
    <span class="n">far</span><span class="p">,</span> <span class="n">frr</span> <span class="o">=</span> <span class="n">farfrr</span><span class="p">(</span><span class="n">negatives</span><span class="p">,</span> <span class="n">positives</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">also_farfrr</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">far</span> <span class="o">+</span> <span class="n">frr</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.0</span><span class="p">,</span> <span class="n">far</span><span class="p">,</span> <span class="n">frr</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">far</span> <span class="o">+</span> <span class="n">frr</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.0</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Idiap Research Institute.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>