<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>bob.measure.binary &mdash; bob.measure 4.2.4b0 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../_static/plot_directive.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="bob.measure.regression" href="bob.measure.regression.html" />
    <link rel="prev" title="Python API" href="../api.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> bob.measure
            <img src="../_static/logo.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                4.2.4b0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../guide.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ci.html">Credible and Confidence Intervals</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../api.html">Python API</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">bob.measure.binary</a></li>
<li class="toctree-l2"><a class="reference internal" href="bob.measure.regression.html">bob.measure.regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="bob.measure.confidence_interval.html">bob.measure.confidence_interval</a></li>
<li class="toctree-l2"><a class="reference internal" href="bob.measure.credible_region.html">bob.measure.credible_region</a></li>
<li class="toctree-l2"><a class="reference internal" href="bob.measure.brute_force.html">bob.measure.brute_force</a></li>
<li class="toctree-l2"><a class="reference internal" href="bob.measure.curves.html">bob.measure.curves</a></li>
<li class="toctree-l2"><a class="reference internal" href="bob.measure.cmc.html">bob.measure.cmc</a></li>
<li class="toctree-l2"><a class="reference internal" href="bob.measure.sensitivity.html">bob.measure.sensitivity</a></li>
<li class="toctree-l2"><a class="reference internal" href="bob.measure.plot.html">bob.measure.plot</a></li>
<li class="toctree-l2"><a class="reference internal" href="bob.measure.load.html">bob.measure.load</a></li>
<li class="toctree-l2"><a class="reference internal" href="bob.measure.calibration.html">bob.measure.calibration</a></li>
<li class="toctree-l2"><a class="reference internal" href="bob.measure.utils.html">bob.measure.utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="bob.measure.plot.html">bob.measure.plot</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../cli.html">Command-Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html">References</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">bob.measure</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../api.html">Python API</a> &raquo;</li>
      <li>bob.measure.binary</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/api/bob.measure.binary.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-bob.measure.binary">
<span id="bob-measure-binary"></span><h1>bob.measure.binary<a class="headerlink" href="#module-bob.measure.binary" title="Permalink to this headline">¶</a></h1>
<p>Basic functions for binary classification performance measurement.</p>
<p>This module contains functions for elementary performance measurement of
<strong>binary classifiers</strong>.  Most of the functions rely on the input of system
output scores for both target (a.k.a.  positives) and non-target (a.k.a.
negatives) samples or integer counts (resulted from pre-thresholding output
scores).</p>
<p>We consider <code class="docutils literal notranslate"><span class="pre">positives</span></code> scores those originating from samples that are
labelled to belong to the class of interest (a.k.a., “signal” or “client”).
<code class="docutils literal notranslate"><span class="pre">negatives</span></code> scores represent system output for input samples that are labeled
<strong>not</strong> to belong to the class of interest (a.k.a., “noise” or “impostor”).  It
is expected that “positive” scores are, at least by design and considering the
intrinsic score scale, typically greater than “negative” scores in a
well-designed classifier.</p>
<p>Every “positive” value that falls bellow the threshold is considered a
false-negative (FN) or a false-rejection (FR).  Analogously, “negative” samples
for which the output score of the system falls above the threshold are
considered a false-positive (FP) or false-acceptance (FA).  Positive scores
that fall on the threshold (exactly) are considered correctly classified
(a.k.a. “true positives”).  Negatives that fall on the threshold (exactly) are
considered <strong>incorrectly</strong> classified (a.k.a. “false positives”).</p>
<p>The “threshold” use to further classify positive and negative scores into true
and false variants does not necessarily have to fall within the range covered
by these scores (negatives and positives altogether).</p>
<p>In practical situations, it is possible that scores are inverted in the
negative/positive sense.  For example, in some setups the designer may have
setup the system so “positive” samples have a smaller score than the “negative”
ones. In this case, make sure you normalize the scores so positive samples have
greater scores before feeding them into these methods, e.g., by multiplying all
scores by -1.</p>
<p class="rubric">Functions</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#bob.measure.binary.accuracy" title="bob.measure.binary.accuracy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">accuracy</span></code></a>(*args)</p></td>
<td><p>Computes the the accuracy of classification</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bob.measure.binary.balanced_accuracy" title="bob.measure.binary.balanced_accuracy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">balanced_accuracy</span></code></a>(*args)</p></td>
<td><p>Computes the the balanced accuracy of classification</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bob.measure.binary.correctly_classified_negatives" title="bob.measure.binary.correctly_classified_negatives"><code class="xref py py-obj docutils literal notranslate"><span class="pre">correctly_classified_negatives</span></code></a>(negatives, ...)</p></td>
<td><p>Evaluates correctly classifed negatives in a set, based on a threshold</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bob.measure.binary.correctly_classified_positives" title="bob.measure.binary.correctly_classified_positives"><code class="xref py py-obj docutils literal notranslate"><span class="pre">correctly_classified_positives</span></code></a>(positives, ...)</p></td>
<td><p>Evaluates correctly classifed positives in a set, based on a threshold</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bob.measure.binary.eer" title="bob.measure.binary.eer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">eer</span></code></a>(negatives, positives[, is_sorted, ...])</p></td>
<td><p>Calculates the Equal Error Rate (EER)</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bob.measure.binary.f1_score" title="bob.measure.binary.f1_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">f1_score</span></code></a>(*args)</p></td>
<td><p>Computes the F-score of the accuracy of the classification</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bob.measure.binary.fall_out" title="bob.measure.binary.fall_out"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fall_out</span></code></a>(*args)</p></td>
<td><p>The false-positive or acceptance rate, or fall-out</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bob.measure.binary.false_acceptance_rate" title="bob.measure.binary.false_acceptance_rate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">false_acceptance_rate</span></code></a>(*args)</p></td>
<td><p>The false-positive or acceptance rate, or fall-out</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bob.measure.binary.false_negative_rate" title="bob.measure.binary.false_negative_rate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">false_negative_rate</span></code></a>(*args)</p></td>
<td><p>The false-negative or rejection rate or miss-rate</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bob.measure.binary.false_negatives" title="bob.measure.binary.false_negatives"><code class="xref py py-obj docutils literal notranslate"><span class="pre">false_negatives</span></code></a>(positives, threshold)</p></td>
<td><p>Evaluates incorrectly classifed positives in a set, based on a threshold</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bob.measure.binary.false_positive_rate" title="bob.measure.binary.false_positive_rate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">false_positive_rate</span></code></a>(*args)</p></td>
<td><p>The false-positive or acceptance rate, or fall-out</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-obj docutils literal notranslate"><span class="pre">false_positives</span></code></a>(negatives, threshold)</p></td>
<td><p>Evaluates incorrectly classifed negatives in a set, based on a threshold</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bob.measure.binary.false_rejection_rate" title="bob.measure.binary.false_rejection_rate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">false_rejection_rate</span></code></a>(*args)</p></td>
<td><p>The false-negative or rejection rate or miss-rate</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bob.measure.binary.farfrr" title="bob.measure.binary.farfrr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">farfrr</span></code></a>(*args)</p></td>
<td><p>Helper to calculate both the FPR (FAR) and FNR (FRR) in one go</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bob.measure.binary.fprfnr" title="bob.measure.binary.fprfnr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fprfnr</span></code></a>(*args)</p></td>
<td><p>Helper to calculate both the FPR (FAR) and FNR (FRR) in one go</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bob.measure.binary.half_total_error_rate" title="bob.measure.binary.half_total_error_rate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">half_total_error_rate</span></code></a>(*args)</p></td>
<td><p>Computes the the half-total error rate (HTER) of classification</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bob.measure.binary.hit_rate" title="bob.measure.binary.hit_rate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hit_rate</span></code></a>(*args)</p></td>
<td><p>The true-positive or acceptance rate, sensitivity, recall or hit rate</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bob.measure.binary.jaccard" title="bob.measure.binary.jaccard"><code class="xref py py-obj docutils literal notranslate"><span class="pre">jaccard</span></code></a>(*args)</p></td>
<td><p>Computes the Jaccard or Similarity index of a classifier</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bob.measure.binary.jaccard_index" title="bob.measure.binary.jaccard_index"><code class="xref py py-obj docutils literal notranslate"><span class="pre">jaccard_index</span></code></a>(*args)</p></td>
<td><p>Computes the Jaccard or Similarity index of a classifier</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bob.measure.binary.matthews_correlation_coefficient" title="bob.measure.binary.matthews_correlation_coefficient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">matthews_correlation_coefficient</span></code></a>(*args)</p></td>
<td><p>Computes the Matthews Correlation Coefficient (MCC) or Phi Coefficient of a classifier</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bob.measure.binary.measures" title="bob.measure.binary.measures"><code class="xref py py-obj docutils literal notranslate"><span class="pre">measures</span></code></a>(*args)</p></td>
<td><p>In a single call, calculate most of the quantities in this module</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bob.measure.binary.miss_rate" title="bob.measure.binary.miss_rate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">miss_rate</span></code></a>(*args)</p></td>
<td><p>The false-negative or rejection rate or miss-rate</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bob.measure.binary.negative_predictive_value" title="bob.measure.binary.negative_predictive_value"><code class="xref py py-obj docutils literal notranslate"><span class="pre">negative_predictive_value</span></code></a>(*args)</p></td>
<td><p>Calculates the negative-predictive value (NPV)</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bob.measure.binary.phi_coefficient" title="bob.measure.binary.phi_coefficient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">phi_coefficient</span></code></a>(*args)</p></td>
<td><p>Computes the Matthews Correlation Coefficient (MCC) or Phi Coefficient of a classifier</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bob.measure.binary.positive_predictive_value" title="bob.measure.binary.positive_predictive_value"><code class="xref py py-obj docutils literal notranslate"><span class="pre">positive_predictive_value</span></code></a>(*args)</p></td>
<td><p>Calculates the precision or positive-predictive value (PPV)</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bob.measure.binary.precision" title="bob.measure.binary.precision"><code class="xref py py-obj docutils literal notranslate"><span class="pre">precision</span></code></a>(*args)</p></td>
<td><p>Calculates the precision or positive-predictive value (PPV)</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bob.measure.binary.precision_recall" title="bob.measure.binary.precision_recall"><code class="xref py py-obj docutils literal notranslate"><span class="pre">precision_recall</span></code></a>(*args)</p></td>
<td><p>Handle to calculate precision and recall in a single call.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bob.measure.binary.recall" title="bob.measure.binary.recall"><code class="xref py py-obj docutils literal notranslate"><span class="pre">recall</span></code></a>(*args)</p></td>
<td><p>The true-positive or acceptance rate, sensitivity, recall or hit rate</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bob.measure.binary.selectivity" title="bob.measure.binary.selectivity"><code class="xref py py-obj docutils literal notranslate"><span class="pre">selectivity</span></code></a>(*args)</p></td>
<td><p>The true-negative or rejection rate, specificity, or selectivity</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bob.measure.binary.sensitivity" title="bob.measure.binary.sensitivity"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sensitivity</span></code></a>(*args)</p></td>
<td><p>The true-positive or acceptance rate, sensitivity, recall or hit rate</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bob.measure.binary.similarly_index" title="bob.measure.binary.similarly_index"><code class="xref py py-obj docutils literal notranslate"><span class="pre">similarly_index</span></code></a>(*args)</p></td>
<td><p>Computes the Jaccard or Similarity index of a classifier</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bob.measure.binary.specificity" title="bob.measure.binary.specificity"><code class="xref py py-obj docutils literal notranslate"><span class="pre">specificity</span></code></a>(*args)</p></td>
<td><p>The true-negative or rejection rate, specificity, or selectivity</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bob.measure.binary.true_acceptance_rate" title="bob.measure.binary.true_acceptance_rate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">true_acceptance_rate</span></code></a>(*args)</p></td>
<td><p>The true-positive or acceptance rate, sensitivity, recall or hit rate</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bob.measure.binary.true_negative_rate" title="bob.measure.binary.true_negative_rate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">true_negative_rate</span></code></a>(*args)</p></td>
<td><p>The true-negative or rejection rate, specificity, or selectivity</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-obj docutils literal notranslate"><span class="pre">true_negatives</span></code></a>(negatives, threshold)</p></td>
<td><p>Evaluates correctly classifed negatives in a set, based on a threshold</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bob.measure.binary.true_positive_rate" title="bob.measure.binary.true_positive_rate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">true_positive_rate</span></code></a>(*args)</p></td>
<td><p>The true-positive or acceptance rate, sensitivity, recall or hit rate</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-obj docutils literal notranslate"><span class="pre">true_positives</span></code></a>(positives, threshold)</p></td>
<td><p>Evaluates correctly classifed positives in a set, based on a threshold</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bob.measure.binary.true_rejection_rate" title="bob.measure.binary.true_rejection_rate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">true_rejection_rate</span></code></a>(*args)</p></td>
<td><p>The true-negative or rejection rate, specificity, or selectivity</p></td>
</tr>
</tbody>
</table>
<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.true_negatives">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">true_negatives</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">negatives</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bob/measure/binary.html#true_negatives"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bob.measure.binary.true_negatives" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates correctly classifed negatives in a set, based on a threshold</p>
<p>This method returns an array composed of booleans that pin-point, which
negatives where correctly classified for the given threshold</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>negatives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for non-target objects, or generated by comparing objects of
different classes</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold, for which scores should be considered to be correctly
classified.  The threshold cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code> (not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>classified</strong> – The decision for each of the <code class="docutils literal notranslate"><span class="pre">negatives</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)">numpy.ndarray</a> (1D, <a class="reference external" href="https://docs.python.org/3.8/library/functions.html#bool" title="(in Python v3.8)">bool</a>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.correctly_classified_negatives">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">correctly_classified_negatives</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">negatives</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bob.measure.binary.correctly_classified_negatives" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates correctly classifed negatives in a set, based on a threshold</p>
<p>This method returns an array composed of booleans that pin-point, which
negatives where correctly classified for the given threshold</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>negatives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for non-target objects, or generated by comparing objects of
different classes</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold, for which scores should be considered to be correctly
classified.  The threshold cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code> (not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>classified</strong> – The decision for each of the <code class="docutils literal notranslate"><span class="pre">negatives</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)">numpy.ndarray</a> (1D, <a class="reference external" href="https://docs.python.org/3.8/library/functions.html#bool" title="(in Python v3.8)">bool</a>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.false_positives">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">false_positives</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">negatives</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bob/measure/binary.html#false_positives"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bob.measure.binary.false_positives" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates incorrectly classifed negatives in a set, based on a threshold</p>
<p>This method returns an array composed of booleans that pin-point, which
negatives where incorrectly classified as positives for the given
threshold.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>negatives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for target objects, or generated by comparing objects of
different classes.</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold, for which scores should be considered to be correctly
classified.  Cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code> (not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>classified</strong> – The decision for each of the <code class="docutils literal notranslate"><span class="pre">negative</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)">numpy.ndarray</a> (1D, <a class="reference external" href="https://docs.python.org/3.8/library/functions.html#bool" title="(in Python v3.8)">bool</a>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.true_positives">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">true_positives</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">positives</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bob/measure/binary.html#true_positives"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bob.measure.binary.true_positives" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates correctly classifed positives in a set, based on a threshold</p>
<p>This method returns an array composed of booleans that pin-point, which
positives where correctly classified for the given threshold.</p>
<p>The pseudo-code for this function is:</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>positives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for target objects, or generated by comparing objects of
the same classe</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold, for which scores should be considered to be correctly
classified.  The threshold cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code> (not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>classified</strong> – The decision for each of the <code class="docutils literal notranslate"><span class="pre">positives</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)">numpy.ndarray</a> (1D, <a class="reference external" href="https://docs.python.org/3.8/library/functions.html#bool" title="(in Python v3.8)">bool</a>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.correctly_classified_positives">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">correctly_classified_positives</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">positives</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bob.measure.binary.correctly_classified_positives" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates correctly classifed positives in a set, based on a threshold</p>
<p>This method returns an array composed of booleans that pin-point, which
positives where correctly classified for the given threshold.</p>
<p>The pseudo-code for this function is:</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>positives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for target objects, or generated by comparing objects of
the same classe</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold, for which scores should be considered to be correctly
classified.  The threshold cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code> (not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>classified</strong> – The decision for each of the <code class="docutils literal notranslate"><span class="pre">positives</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)">numpy.ndarray</a> (1D, <a class="reference external" href="https://docs.python.org/3.8/library/functions.html#bool" title="(in Python v3.8)">bool</a>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.false_negatives">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">false_negatives</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">positives</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bob/measure/binary.html#false_negatives"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bob.measure.binary.false_negatives" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates incorrectly classifed positives in a set, based on a threshold</p>
<p>This method returns an array composed of booleans that pin-point, which
positives where incorrectly classified for the given threshold</p>
<p>The pseudo-code for this function is:</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>positives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for target objects, or generated by comparing objects of
the same class</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold, for which scores should be considered to be correctly
classified.  The threshold cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code> (not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>classified</strong> – The decision (if incorrectly classified) for each of the <code class="docutils literal notranslate"><span class="pre">positives</span></code>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)">numpy.ndarray</a> (1D, <a class="reference external" href="https://docs.python.org/3.8/library/functions.html#bool" title="(in Python v3.8)">bool</a>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.true_negative_rate">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">true_negative_rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bob/measure/binary.html#true_negative_rate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bob.measure.binary.true_negative_rate" title="Permalink to this definition">¶</a></dt>
<dd><p>The true-negative or rejection rate, specificity, or selectivity</p>
<p>By definition, the true-negative rate, specificity, or selectivity is the
ratio between the number of true negatives and the total number of
negatives.  If the number of negative scores is zero, this function
exceptionally returns 0.0 instead of <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
<p>This function accepts 2 signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">true_negative_rate(tn:</span> <span class="pre">int,</span> <span class="pre">ttn:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">true_negative_rate(negatives:</span> <span class="pre">Sequence[float],</span> <span class="pre">threshold:</span> <span class="pre">float)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a> and total negatives,
pre-calculated.</p></li>
<li><p><strong>ttn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a> and total negatives,
pre-calculated.</p></li>
<li><p><strong>negatives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for target objects, or generated by comparing objects of
different classes</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to separate correctly and incorrectly classified scores.
Cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code> (not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>tnr</strong> – The True Negative Rate (tnr) for the given threshold</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.specificity">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">specificity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bob.measure.binary.specificity" title="Permalink to this definition">¶</a></dt>
<dd><p>The true-negative or rejection rate, specificity, or selectivity</p>
<p>By definition, the true-negative rate, specificity, or selectivity is the
ratio between the number of true negatives and the total number of
negatives.  If the number of negative scores is zero, this function
exceptionally returns 0.0 instead of <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
<p>This function accepts 2 signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">true_negative_rate(tn:</span> <span class="pre">int,</span> <span class="pre">ttn:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">true_negative_rate(negatives:</span> <span class="pre">Sequence[float],</span> <span class="pre">threshold:</span> <span class="pre">float)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a> and total negatives,
pre-calculated.</p></li>
<li><p><strong>ttn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a> and total negatives,
pre-calculated.</p></li>
<li><p><strong>negatives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for target objects, or generated by comparing objects of
different classes</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to separate correctly and incorrectly classified scores.
Cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code> (not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>tnr</strong> – The True Negative Rate (tnr) for the given threshold</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.selectivity">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">selectivity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bob.measure.binary.selectivity" title="Permalink to this definition">¶</a></dt>
<dd><p>The true-negative or rejection rate, specificity, or selectivity</p>
<p>By definition, the true-negative rate, specificity, or selectivity is the
ratio between the number of true negatives and the total number of
negatives.  If the number of negative scores is zero, this function
exceptionally returns 0.0 instead of <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
<p>This function accepts 2 signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">true_negative_rate(tn:</span> <span class="pre">int,</span> <span class="pre">ttn:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">true_negative_rate(negatives:</span> <span class="pre">Sequence[float],</span> <span class="pre">threshold:</span> <span class="pre">float)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a> and total negatives,
pre-calculated.</p></li>
<li><p><strong>ttn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a> and total negatives,
pre-calculated.</p></li>
<li><p><strong>negatives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for target objects, or generated by comparing objects of
different classes</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to separate correctly and incorrectly classified scores.
Cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code> (not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>tnr</strong> – The True Negative Rate (tnr) for the given threshold</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.true_rejection_rate">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">true_rejection_rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bob.measure.binary.true_rejection_rate" title="Permalink to this definition">¶</a></dt>
<dd><p>The true-negative or rejection rate, specificity, or selectivity</p>
<p>By definition, the true-negative rate, specificity, or selectivity is the
ratio between the number of true negatives and the total number of
negatives.  If the number of negative scores is zero, this function
exceptionally returns 0.0 instead of <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
<p>This function accepts 2 signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">true_negative_rate(tn:</span> <span class="pre">int,</span> <span class="pre">ttn:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">true_negative_rate(negatives:</span> <span class="pre">Sequence[float],</span> <span class="pre">threshold:</span> <span class="pre">float)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a> and total negatives,
pre-calculated.</p></li>
<li><p><strong>ttn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a> and total negatives,
pre-calculated.</p></li>
<li><p><strong>negatives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for target objects, or generated by comparing objects of
different classes</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to separate correctly and incorrectly classified scores.
Cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code> (not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>tnr</strong> – The True Negative Rate (tnr) for the given threshold</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.false_positive_rate">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">false_positive_rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bob/measure/binary.html#false_positive_rate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bob.measure.binary.false_positive_rate" title="Permalink to this definition">¶</a></dt>
<dd><p>The false-positive or acceptance rate, or fall-out</p>
<p>By definition, the false-positive rate or fall-out is the ratio between the
number of false positives and the total number of negatives.  If the number
of negative scores is zero, this function exceptionally returns 0.0 instead
of <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
<p>This function accepts 2 signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">false_positive_rate(fp:</span> <span class="pre">int,</span> <span class="pre">ttn:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">false_positive_rate(negatives:</span> <span class="pre">Sequence[float],</span> <span class="pre">threshold:</span> <span class="pre">float)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a> and total negatives,
pre-calculated.</p></li>
<li><p><strong>ttn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a> and total negatives,
pre-calculated.</p></li>
<li><p><strong>negatives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for non-target objects, or generated by comparing objects of
different classes</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to separate correctly and incorrectly classified scores.
Cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code> (not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>fpr</strong> – The False Positve Rate (FPR) for the given threshold.  If the number of
negative scores is zero, this function exceptionally returns 0.0
instead of <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.fall_out">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">fall_out</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bob.measure.binary.fall_out" title="Permalink to this definition">¶</a></dt>
<dd><p>The false-positive or acceptance rate, or fall-out</p>
<p>By definition, the false-positive rate or fall-out is the ratio between the
number of false positives and the total number of negatives.  If the number
of negative scores is zero, this function exceptionally returns 0.0 instead
of <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
<p>This function accepts 2 signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">false_positive_rate(fp:</span> <span class="pre">int,</span> <span class="pre">ttn:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">false_positive_rate(negatives:</span> <span class="pre">Sequence[float],</span> <span class="pre">threshold:</span> <span class="pre">float)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a> and total negatives,
pre-calculated.</p></li>
<li><p><strong>ttn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a> and total negatives,
pre-calculated.</p></li>
<li><p><strong>negatives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for non-target objects, or generated by comparing objects of
different classes</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to separate correctly and incorrectly classified scores.
Cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code> (not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>fpr</strong> – The False Positve Rate (FPR) for the given threshold.  If the number of
negative scores is zero, this function exceptionally returns 0.0
instead of <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.false_acceptance_rate">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">false_acceptance_rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bob.measure.binary.false_acceptance_rate" title="Permalink to this definition">¶</a></dt>
<dd><p>The false-positive or acceptance rate, or fall-out</p>
<p>By definition, the false-positive rate or fall-out is the ratio between the
number of false positives and the total number of negatives.  If the number
of negative scores is zero, this function exceptionally returns 0.0 instead
of <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
<p>This function accepts 2 signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">false_positive_rate(fp:</span> <span class="pre">int,</span> <span class="pre">ttn:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">false_positive_rate(negatives:</span> <span class="pre">Sequence[float],</span> <span class="pre">threshold:</span> <span class="pre">float)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a> and total negatives,
pre-calculated.</p></li>
<li><p><strong>ttn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a> and total negatives,
pre-calculated.</p></li>
<li><p><strong>negatives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for non-target objects, or generated by comparing objects of
different classes</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to separate correctly and incorrectly classified scores.
Cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code> (not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>fpr</strong> – The False Positve Rate (FPR) for the given threshold.  If the number of
negative scores is zero, this function exceptionally returns 0.0
instead of <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.true_positive_rate">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">true_positive_rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bob/measure/binary.html#true_positive_rate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bob.measure.binary.true_positive_rate" title="Permalink to this definition">¶</a></dt>
<dd><p>The true-positive or acceptance rate, sensitivity, recall or hit rate</p>
<p>By definition, the true-positive rate, sensitivity, recall or hit-rate is
the ratio between the number of true positives and the total number of
positives.  If the number of positives is zero, this function exceptionally
returns 0.0 instead of <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
<p>This function accepts 2 signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">true_positive_rate(tp:</span> <span class="pre">int,</span> <span class="pre">ttp:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">true_positive_rate(positives:</span> <span class="pre">Sequence[float],</span> <span class="pre">threshold:</span> <span class="pre">float)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a> and total number of positive
scores, pre-calculated.</p></li>
<li><p><strong>ttp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a> and total number of positive
scores, pre-calculated.</p></li>
<li><p><strong>positives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for target objects, or generated by comparing objects of
the same class</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to separate correctly and incorrectly classified scores.
Cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code> (not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>tpr</strong> – The True Positive Rate (tpr) for the given threshold.  If the number of
positives is zero, this function exceptionally returns 0.0 instead of
<code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.sensitivity">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">sensitivity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bob.measure.binary.sensitivity" title="Permalink to this definition">¶</a></dt>
<dd><p>The true-positive or acceptance rate, sensitivity, recall or hit rate</p>
<p>By definition, the true-positive rate, sensitivity, recall or hit-rate is
the ratio between the number of true positives and the total number of
positives.  If the number of positives is zero, this function exceptionally
returns 0.0 instead of <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
<p>This function accepts 2 signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">true_positive_rate(tp:</span> <span class="pre">int,</span> <span class="pre">ttp:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">true_positive_rate(positives:</span> <span class="pre">Sequence[float],</span> <span class="pre">threshold:</span> <span class="pre">float)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a> and total number of positive
scores, pre-calculated.</p></li>
<li><p><strong>ttp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a> and total number of positive
scores, pre-calculated.</p></li>
<li><p><strong>positives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for target objects, or generated by comparing objects of
the same class</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to separate correctly and incorrectly classified scores.
Cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code> (not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>tpr</strong> – The True Positive Rate (tpr) for the given threshold.  If the number of
positives is zero, this function exceptionally returns 0.0 instead of
<code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.recall">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">recall</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bob.measure.binary.recall" title="Permalink to this definition">¶</a></dt>
<dd><p>The true-positive or acceptance rate, sensitivity, recall or hit rate</p>
<p>By definition, the true-positive rate, sensitivity, recall or hit-rate is
the ratio between the number of true positives and the total number of
positives.  If the number of positives is zero, this function exceptionally
returns 0.0 instead of <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
<p>This function accepts 2 signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">true_positive_rate(tp:</span> <span class="pre">int,</span> <span class="pre">ttp:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">true_positive_rate(positives:</span> <span class="pre">Sequence[float],</span> <span class="pre">threshold:</span> <span class="pre">float)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a> and total number of positive
scores, pre-calculated.</p></li>
<li><p><strong>ttp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a> and total number of positive
scores, pre-calculated.</p></li>
<li><p><strong>positives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for target objects, or generated by comparing objects of
the same class</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to separate correctly and incorrectly classified scores.
Cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code> (not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>tpr</strong> – The True Positive Rate (tpr) for the given threshold.  If the number of
positives is zero, this function exceptionally returns 0.0 instead of
<code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.hit_rate">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">hit_rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bob.measure.binary.hit_rate" title="Permalink to this definition">¶</a></dt>
<dd><p>The true-positive or acceptance rate, sensitivity, recall or hit rate</p>
<p>By definition, the true-positive rate, sensitivity, recall or hit-rate is
the ratio between the number of true positives and the total number of
positives.  If the number of positives is zero, this function exceptionally
returns 0.0 instead of <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
<p>This function accepts 2 signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">true_positive_rate(tp:</span> <span class="pre">int,</span> <span class="pre">ttp:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">true_positive_rate(positives:</span> <span class="pre">Sequence[float],</span> <span class="pre">threshold:</span> <span class="pre">float)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a> and total number of positive
scores, pre-calculated.</p></li>
<li><p><strong>ttp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a> and total number of positive
scores, pre-calculated.</p></li>
<li><p><strong>positives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for target objects, or generated by comparing objects of
the same class</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to separate correctly and incorrectly classified scores.
Cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code> (not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>tpr</strong> – The True Positive Rate (tpr) for the given threshold.  If the number of
positives is zero, this function exceptionally returns 0.0 instead of
<code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.true_acceptance_rate">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">true_acceptance_rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bob.measure.binary.true_acceptance_rate" title="Permalink to this definition">¶</a></dt>
<dd><p>The true-positive or acceptance rate, sensitivity, recall or hit rate</p>
<p>By definition, the true-positive rate, sensitivity, recall or hit-rate is
the ratio between the number of true positives and the total number of
positives.  If the number of positives is zero, this function exceptionally
returns 0.0 instead of <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
<p>This function accepts 2 signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">true_positive_rate(tp:</span> <span class="pre">int,</span> <span class="pre">ttp:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">true_positive_rate(positives:</span> <span class="pre">Sequence[float],</span> <span class="pre">threshold:</span> <span class="pre">float)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a> and total number of positive
scores, pre-calculated.</p></li>
<li><p><strong>ttp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a> and total number of positive
scores, pre-calculated.</p></li>
<li><p><strong>positives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for target objects, or generated by comparing objects of
the same class</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to separate correctly and incorrectly classified scores.
Cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code> (not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>tpr</strong> – The True Positive Rate (tpr) for the given threshold.  If the number of
positives is zero, this function exceptionally returns 0.0 instead of
<code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.false_negative_rate">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">false_negative_rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bob/measure/binary.html#false_negative_rate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bob.measure.binary.false_negative_rate" title="Permalink to this definition">¶</a></dt>
<dd><p>The false-negative or rejection rate or miss-rate</p>
<p>By definition, the false-negative rate or miss-rate is the ratio between
the number of false negatives and the total number of positives. If the
number of positives is zero, this function exceptionally returns 0.0
instead of <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
<p>This function accepts 2 signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">false_negative_rate(fn:</span> <span class="pre">int,</span> <span class="pre">ttp:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">false_negative_rate(positives:</span> <span class="pre">Sequence[float],</span> <span class="pre">threshold:</span> <span class="pre">float)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_negatives" title="bob.measure.binary.false_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_negatives()</span></code></a> and total positives,
pre-calculated.</p></li>
<li><p><strong>ttp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_negatives" title="bob.measure.binary.false_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_negatives()</span></code></a> and total positives,
pre-calculated.</p></li>
<li><p><strong>positives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for target objects, or generated by comparing objects of
the same class</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to separate correctly and incorrectly classified scores.
The threshold cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code> (not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>fnr</strong> – The False Negative Rate (FPR) for the given threshold.  If the number
of positives is zero, this function exceptionally returns 0.0 instead
of <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.miss_rate">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">miss_rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bob.measure.binary.miss_rate" title="Permalink to this definition">¶</a></dt>
<dd><p>The false-negative or rejection rate or miss-rate</p>
<p>By definition, the false-negative rate or miss-rate is the ratio between
the number of false negatives and the total number of positives. If the
number of positives is zero, this function exceptionally returns 0.0
instead of <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
<p>This function accepts 2 signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">false_negative_rate(fn:</span> <span class="pre">int,</span> <span class="pre">ttp:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">false_negative_rate(positives:</span> <span class="pre">Sequence[float],</span> <span class="pre">threshold:</span> <span class="pre">float)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_negatives" title="bob.measure.binary.false_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_negatives()</span></code></a> and total positives,
pre-calculated.</p></li>
<li><p><strong>ttp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_negatives" title="bob.measure.binary.false_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_negatives()</span></code></a> and total positives,
pre-calculated.</p></li>
<li><p><strong>positives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for target objects, or generated by comparing objects of
the same class</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to separate correctly and incorrectly classified scores.
The threshold cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code> (not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>fnr</strong> – The False Negative Rate (FPR) for the given threshold.  If the number
of positives is zero, this function exceptionally returns 0.0 instead
of <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.false_rejection_rate">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">false_rejection_rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bob.measure.binary.false_rejection_rate" title="Permalink to this definition">¶</a></dt>
<dd><p>The false-negative or rejection rate or miss-rate</p>
<p>By definition, the false-negative rate or miss-rate is the ratio between
the number of false negatives and the total number of positives. If the
number of positives is zero, this function exceptionally returns 0.0
instead of <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
<p>This function accepts 2 signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">false_negative_rate(fn:</span> <span class="pre">int,</span> <span class="pre">ttp:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">false_negative_rate(positives:</span> <span class="pre">Sequence[float],</span> <span class="pre">threshold:</span> <span class="pre">float)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_negatives" title="bob.measure.binary.false_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_negatives()</span></code></a> and total positives,
pre-calculated.</p></li>
<li><p><strong>ttp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_negatives" title="bob.measure.binary.false_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_negatives()</span></code></a> and total positives,
pre-calculated.</p></li>
<li><p><strong>positives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for target objects, or generated by comparing objects of
the same class</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to separate correctly and incorrectly classified scores.
The threshold cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code> (not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>fnr</strong> – The False Negative Rate (FPR) for the given threshold.  If the number
of positives is zero, this function exceptionally returns 0.0 instead
of <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.precision">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">precision</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bob/measure/binary.html#precision"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bob.measure.binary.precision" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the precision or positive-predictive value (PPV)</p>
<p>The precision or positive predictive value (PPV) is defined by:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\\mathrm{ppv} = \\frac{tp}{tp + fp}\end{split}\]</div>
<p>Notice that, in the case <code class="docutils literal notranslate"><span class="pre">tp+fp</span> <span class="pre">==</span> <span class="pre">0</span></code>, this function returns 0.0,
exceptionally.  TP and FP may be calculated from both <code class="docutils literal notranslate"><span class="pre">negative</span></code> and
<code class="docutils literal notranslate"><span class="pre">positive</span></code> scores if a threshold is also provided.  This function has two
signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">precision(fp:</span> <span class="pre">int,</span> <span class="pre">tp:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">precision(negatives:</span> <span class="pre">Sequence[float],</span> <span class="pre">positives:</span> <span class="pre">Sequence[float],</span> <span class="pre">threshold:</span> <span class="pre">float)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a> and <a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a>,
pre-calculated.</p></li>
<li><p><strong>tp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a> and <a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a>,
pre-calculated.</p></li>
<li><p><strong>negatives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The set of negative and positive scores to compute the measurement</p></li>
<li><p><strong>positives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The set of negative and positive scores to compute the measurement</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to compute the measures for.  Cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.  Only
useful if arrays of <code class="docutils literal notranslate"><span class="pre">negatives</span></code> and <code class="docutils literal notranslate"><span class="pre">positives</span></code> are provided.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>precision</strong> – The precision.  Notice that, in the case <code class="docutils literal notranslate"><span class="pre">tn+fn</span> <span class="pre">==</span> <span class="pre">0</span></code>, this function
returns 0.0, exceptionally.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.positive_predictive_value">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">positive_predictive_value</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bob.measure.binary.positive_predictive_value" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the precision or positive-predictive value (PPV)</p>
<p>The precision or positive predictive value (PPV) is defined by:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\\mathrm{ppv} = \\frac{tp}{tp + fp}\end{split}\]</div>
<p>Notice that, in the case <code class="docutils literal notranslate"><span class="pre">tp+fp</span> <span class="pre">==</span> <span class="pre">0</span></code>, this function returns 0.0,
exceptionally.  TP and FP may be calculated from both <code class="docutils literal notranslate"><span class="pre">negative</span></code> and
<code class="docutils literal notranslate"><span class="pre">positive</span></code> scores if a threshold is also provided.  This function has two
signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">precision(fp:</span> <span class="pre">int,</span> <span class="pre">tp:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">precision(negatives:</span> <span class="pre">Sequence[float],</span> <span class="pre">positives:</span> <span class="pre">Sequence[float],</span> <span class="pre">threshold:</span> <span class="pre">float)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a> and <a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a>,
pre-calculated.</p></li>
<li><p><strong>tp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a> and <a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a>,
pre-calculated.</p></li>
<li><p><strong>negatives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The set of negative and positive scores to compute the measurement</p></li>
<li><p><strong>positives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The set of negative and positive scores to compute the measurement</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to compute the measures for.  Cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.  Only
useful if arrays of <code class="docutils literal notranslate"><span class="pre">negatives</span></code> and <code class="docutils literal notranslate"><span class="pre">positives</span></code> are provided.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>precision</strong> – The precision.  Notice that, in the case <code class="docutils literal notranslate"><span class="pre">tn+fn</span> <span class="pre">==</span> <span class="pre">0</span></code>, this function
returns 0.0, exceptionally.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.negative_predictive_value">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">negative_predictive_value</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bob/measure/binary.html#negative_predictive_value"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bob.measure.binary.negative_predictive_value" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the negative-predictive value (NPV)</p>
<p>The negative predictive value (NPV) is defined by:</p>
<div class="math notranslate nohighlight">
\[\mathrm{npv} = \frac{tn}{tn + fn}\]</div>
<p>Notice that, in the case <code class="docutils literal notranslate"><span class="pre">tn+fn</span> <span class="pre">==</span> <span class="pre">0</span></code>, this function returns 0.0,
exceptionally.  TP and FP may be calculated from both <code class="docutils literal notranslate"><span class="pre">negative</span></code> and
<code class="docutils literal notranslate"><span class="pre">positive</span></code> scores if a threshold is also provided.  This function has two
signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">negative_predictive_value(tn:</span> <span class="pre">int,</span> <span class="pre">fn:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">negative_predictive_value(negatives:</span> <span class="pre">Sequence[float],</span> <span class="pre">positives:</span> <span class="pre">Sequence[float],</span> <span class="pre">threshold:</span> <span class="pre">float)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a> and <a class="reference internal" href="#bob.measure.binary.false_negatives" title="bob.measure.binary.false_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_negatives()</span></code></a>,
pre-calculated.</p></li>
<li><p><strong>fn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a> and <a class="reference internal" href="#bob.measure.binary.false_negatives" title="bob.measure.binary.false_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_negatives()</span></code></a>,
pre-calculated.</p></li>
<li><p><strong>negatives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The set of negative and positive scores to compute the measurement</p></li>
<li><p><strong>positives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The set of negative and positive scores to compute the measurement</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to compute the measures for.  Cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.  Only
useful if arrays of <code class="docutils literal notranslate"><span class="pre">negatives</span></code> and <code class="docutils literal notranslate"><span class="pre">positives</span></code> are provided.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>npv</strong> – The negative-predictive value for the given negatives and positives, at
a given threshold.  Notice that, in the case <code class="docutils literal notranslate"><span class="pre">tn+fn</span> <span class="pre">==</span> <span class="pre">0</span></code>, this
function returns 0.0, exceptionally.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.precision_recall">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">precision_recall</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bob/measure/binary.html#precision_recall"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bob.measure.binary.precision_recall" title="Permalink to this definition">¶</a></dt>
<dd><p>Handle to calculate precision and recall in a single call.</p>
<p>See:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#bob.measure.binary.precision" title="bob.measure.binary.precision"><code class="xref py py-func docutils literal notranslate"><span class="pre">precision()</span></code></a></p></li>
<li><p><a class="reference internal" href="#bob.measure.binary.recall" title="bob.measure.binary.recall"><code class="xref py py-func docutils literal notranslate"><span class="pre">recall()</span></code></a></p></li>
</ul>
<p>This function has two signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">precision_recall(fp:</span> <span class="pre">int,</span> <span class="pre">tp:</span> <span class="pre">int,</span> <span class="pre">ttp:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">(float,</span> <span class="pre">float)</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">precision_recall(negatives:</span> <span class="pre">Sequence[float],</span> <span class="pre">positives:</span> <span class="pre">Sequence[float],</span> <span class="pre">threshold:</span> <span class="pre">float)</span> <span class="pre">-&gt;</span> <span class="pre">(float,</span> <span class="pre">float)</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a>, <a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a>,
and total number of positive scores, pre-calculated.</p></li>
<li><p><strong>tp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a>, <a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a>,
and total number of positive scores, pre-calculated.</p></li>
<li><p><strong>ttp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a>, <a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a>,
and total number of positive scores, pre-calculated.</p></li>
<li><p><strong>negatives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The set of negative and positive scores to compute the measurements</p></li>
<li><p><strong>positives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The set of negative and positive scores to compute the measurements</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to compute the measures for</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>precision</strong> (<em>float</em>) – The precision value for the given negatives and positives</p></li>
<li><p><strong>recall</strong> (<em>float</em>) – The recall value for the given negatives and positives</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.fprfnr">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">fprfnr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bob/measure/binary.html#fprfnr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bob.measure.binary.fprfnr" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper to calculate both the FPR (FAR) and FNR (FRR) in one go</p>
<p>See:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#bob.measure.binary.false_positive_rate" title="bob.measure.binary.false_positive_rate"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positive_rate()</span></code></a></p></li>
<li><p><a class="reference internal" href="#bob.measure.binary.false_negative_rate" title="bob.measure.binary.false_negative_rate"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_negative_rate()</span></code></a></p></li>
</ul>
<p>This function has two signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">fprfnr(fp:</span> <span class="pre">int,</span> <span class="pre">ttn:</span> <span class="pre">int,</span> <span class="pre">fn:</span> <span class="pre">int,</span> <span class="pre">ttp:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">(float,</span> <span class="pre">float)</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fprfnr(negatives:</span> <span class="pre">Sequence[float],</span> <span class="pre">positives:</span> <span class="pre">Sequence[float],</span> <span class="pre">threshold:</span> <span class="pre">float)</span> <span class="pre">-&gt;</span> <span class="pre">(float,</span> <span class="pre">float)</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a>, total negatives,
<a class="reference internal" href="#bob.measure.binary.false_negatives" title="bob.measure.binary.false_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_negatives()</span></code></a>, and total positives, pre-calculated.</p></li>
<li><p><strong>ttn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a>, total negatives,
<a class="reference internal" href="#bob.measure.binary.false_negatives" title="bob.measure.binary.false_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_negatives()</span></code></a>, and total positives, pre-calculated.</p></li>
<li><p><strong>fn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a>, total negatives,
<a class="reference internal" href="#bob.measure.binary.false_negatives" title="bob.measure.binary.false_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_negatives()</span></code></a>, and total positives, pre-calculated.</p></li>
<li><p><strong>ttp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a>, total negatives,
<a class="reference internal" href="#bob.measure.binary.false_negatives" title="bob.measure.binary.false_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_negatives()</span></code></a>, and total positives, pre-calculated.</p></li>
<li><p><strong>negatives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for non-target and target samples</p></li>
<li><p><strong>positives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for non-target and target samples</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to separate correctly and incorrectly classified scores</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>fpr</strong> (<em>float</em>) – The False Positve Rate (FPR) or False Acceptance Rate (FAR) for the
given threshold</p></li>
<li><p><strong>fnr</strong> (<em>float</em>) – The False Negative Rate (FNR) or False Reject Rate (FRR) for the given
threshold</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.farfrr">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">farfrr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bob.measure.binary.farfrr" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper to calculate both the FPR (FAR) and FNR (FRR) in one go</p>
<p>See:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#bob.measure.binary.false_positive_rate" title="bob.measure.binary.false_positive_rate"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positive_rate()</span></code></a></p></li>
<li><p><a class="reference internal" href="#bob.measure.binary.false_negative_rate" title="bob.measure.binary.false_negative_rate"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_negative_rate()</span></code></a></p></li>
</ul>
<p>This function has two signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">fprfnr(fp:</span> <span class="pre">int,</span> <span class="pre">ttn:</span> <span class="pre">int,</span> <span class="pre">fn:</span> <span class="pre">int,</span> <span class="pre">ttp:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">(float,</span> <span class="pre">float)</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fprfnr(negatives:</span> <span class="pre">Sequence[float],</span> <span class="pre">positives:</span> <span class="pre">Sequence[float],</span> <span class="pre">threshold:</span> <span class="pre">float)</span> <span class="pre">-&gt;</span> <span class="pre">(float,</span> <span class="pre">float)</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a>, total negatives,
<a class="reference internal" href="#bob.measure.binary.false_negatives" title="bob.measure.binary.false_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_negatives()</span></code></a>, and total positives, pre-calculated.</p></li>
<li><p><strong>ttn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a>, total negatives,
<a class="reference internal" href="#bob.measure.binary.false_negatives" title="bob.measure.binary.false_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_negatives()</span></code></a>, and total positives, pre-calculated.</p></li>
<li><p><strong>fn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a>, total negatives,
<a class="reference internal" href="#bob.measure.binary.false_negatives" title="bob.measure.binary.false_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_negatives()</span></code></a>, and total positives, pre-calculated.</p></li>
<li><p><strong>ttp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a>, total negatives,
<a class="reference internal" href="#bob.measure.binary.false_negatives" title="bob.measure.binary.false_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_negatives()</span></code></a>, and total positives, pre-calculated.</p></li>
<li><p><strong>negatives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for non-target and target samples</p></li>
<li><p><strong>positives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for non-target and target samples</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to separate correctly and incorrectly classified scores</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>fpr</strong> (<em>float</em>) – The False Positve Rate (FPR) or False Acceptance Rate (FAR) for the
given threshold</p></li>
<li><p><strong>fnr</strong> (<em>float</em>) – The False Negative Rate (FNR) or False Reject Rate (FRR) for the given
threshold</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.f1_score">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">f1_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bob/measure/binary.html#f1_score"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bob.measure.binary.f1_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the F-score of the accuracy of the classification</p>
<p>The F-score is a weighted mean of precision and recall measurements, see
<a class="reference internal" href="#bob.measure.binary.precision_recall" title="bob.measure.binary.precision_recall"><code class="xref py py-func docutils literal notranslate"><span class="pre">precision_recall()</span></code></a>.  It is computed as:</p>
<div class="math notranslate nohighlight">
\[\mathrm{\text{f-score}}(w) = (1 + w^2)\frac{\mathrm{precision}\cdot{}\mathrm{recall}}{w^2\cdot{}\mathrm{precision} + \mathrm{recall}}\]</div>
<p>The weight <span class="math notranslate nohighlight">\(w\)</span> needs to be non-negative real value. In case the
weight parameter is 1 (current implementation), the F-score is called F1
score and represents the harmonic mean between precision and recall values.
This function exceptionally returns <code class="docutils literal notranslate"><span class="pre">0.0</span></code> if the denominator above is
zero.</p>
<p>This function has two signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">f1_score(fp:</span> <span class="pre">int,</span> <span class="pre">tp:</span> <span class="pre">int,</span> <span class="pre">ttn:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">f1_score(negatives:</span> <span class="pre">Sequence[float],</span> <span class="pre">positives:</span> <span class="pre">Sequence[float],</span> <span class="pre">threshold:</span> <span class="pre">float)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a>, <a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a>,
and total negatives, pre-calculated.</p></li>
<li><p><strong>tp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a>, <a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a>,
and total negatives, pre-calculated.</p></li>
<li><p><strong>ttn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a>, <a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a>,
and total negatives, pre-calculated.</p></li>
<li><p><strong>negatives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for non-target and target samples</p></li>
<li><p><strong>positives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for non-target and target samples</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to compute the f1-score for.  Cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code>
(not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>f1_score</strong> – The computed F1-score</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.accuracy">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">accuracy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bob/measure/binary.html#accuracy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bob.measure.binary.accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the the accuracy of classification</p>
<p>Accuracy is the proportion of correct predictions (both true positives and
true negatives) among the total number of elements examined.  It
corresponds arithmetically to:</p>
<div class="math notranslate nohighlight">
\begin{align*}
    \mathrm{Acc} &amp;= \frac{\mathrm{tn}+\mathrm{tp}}{\mathrm{tn}+\mathrm{fp}+\mathrm{tp}+\mathrm{fn}} \\
    \mathrm{Acc} &amp;= \frac{\mathrm{tn}+\mathrm{tp}}{\mathrm{ttn}+\mathrm{ttp}}
\end{align*}</div><p>In the special case where <code class="docutils literal notranslate"><span class="pre">ttn+ttp</span> <span class="pre">==</span> <span class="pre">0</span></code>, this function returns zero for
accuracy.</p>
<p>Because it considers both TP and TN in the numerator, this measure is
sensitive to threshold domains which may be completely dominated by true
positive or negative scores.</p>
<p>This function has two signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">accuracy(tn:</span> <span class="pre">int,</span> <span class="pre">ttn:</span> <span class="pre">int,</span> <span class="pre">tp:</span> <span class="pre">int,</span> <span class="pre">ttp:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">accuracy(negatives:</span> <span class="pre">Sequence[float],</span> <span class="pre">positives:</span> <span class="pre">Sequence[float],</span> <span class="pre">threshold:</span> <span class="pre">float)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a>, total negatives,
<a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a>, total positives, pre-calculated.</p></li>
<li><p><strong>ttn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a>, total negatives,
<a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a>, total positives, pre-calculated.</p></li>
<li><p><strong>tp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a>, total negatives,
<a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a>, total positives, pre-calculated.</p></li>
<li><p><strong>ttp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a>, total negatives,
<a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a>, total positives, pre-calculated.</p></li>
<li><p><strong>negatives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for non-target and target samples</p></li>
<li><p><strong>positives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for non-target and target samples</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to compute the accuracy for.  Cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code>
(not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>acc</strong> – The computed accuracy</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.balanced_accuracy">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">balanced_accuracy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bob/measure/binary.html#balanced_accuracy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bob.measure.binary.balanced_accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the the balanced accuracy of classification</p>
<p>Balance accuracy corresponds arithmetically to:</p>
<div class="math notranslate nohighlight">
\[\mathrm{BA} = \frac{\mathrm{tnr}+\mathrm{tpr}}{2}\]</div>
<p>This function has two signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">balanced_accuracy(tn:</span> <span class="pre">int,</span> <span class="pre">ttn:</span> <span class="pre">int,</span> <span class="pre">tp:</span> <span class="pre">int,</span> <span class="pre">ttp:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">balanced_accuracy(negatives:</span> <span class="pre">Sequence[float],</span> <span class="pre">positives:</span> <span class="pre">Sequence[float],</span> <span class="pre">threshold:</span> <span class="pre">float)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a>, total negatives,
<a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a>, total positives, pre-calculated.</p></li>
<li><p><strong>ttn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a>, total negatives,
<a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a>, total positives, pre-calculated.</p></li>
<li><p><strong>tp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a>, total negatives,
<a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a>, total positives, pre-calculated.</p></li>
<li><p><strong>ttp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a>, total negatives,
<a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a>, total positives, pre-calculated.</p></li>
<li><p><strong>negatives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for non-target and target samples</p></li>
<li><p><strong>positives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for non-target and target samples</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to compute the balanced accuracy for.  Cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code>
(not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>ba</strong> – The computed balanced accuracy</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.half_total_error_rate">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">half_total_error_rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bob/measure/binary.html#half_total_error_rate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bob.measure.binary.half_total_error_rate" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the the half-total error rate (HTER) of classification</p>
<p>The HTER corresponds arithmetically to:</p>
<div class="math notranslate nohighlight">
\begin{align*}
    \mathrm{HTER} &amp;= \frac{\mathrm{fpr}+\mathrm{fnr}}{2} \\
    \mathrm{HTER} &amp;= \frac{(1-\mathrm{tnr})+(1-\mathrm{tpr})}{2} \\
    \mathrm{HTER} &amp;= 1 - \frac{\mathrm{tnr}+\mathrm{tpr}}{2} \\
    \mathrm{HTER} &amp;= 1 - BA
\end{align*}</div><ul class="simple">
<li><p>See <a class="reference internal" href="#bob.measure.binary.balanced_accuracy" title="bob.measure.binary.balanced_accuracy"><code class="xref py py-func docutils literal notranslate"><span class="pre">balanced_accuracy()</span></code></a></p></li>
</ul>
<p>This function has two signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">half_total_error_rate(tn:</span> <span class="pre">int,</span> <span class="pre">ttn:</span> <span class="pre">int,</span> <span class="pre">tp:</span> <span class="pre">int,</span> <span class="pre">ttp:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">half_total_error_rate(negatives:</span> <span class="pre">Sequence[float],</span> <span class="pre">positives:</span> <span class="pre">Sequence[float],</span> <span class="pre">threshold:</span> <span class="pre">float)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a>, total negatives,
<a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a>, total positives, pre-calculated.</p></li>
<li><p><strong>ttn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a>, total negatives,
<a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a>, total positives, pre-calculated.</p></li>
<li><p><strong>tp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a>, total negatives,
<a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a>, total positives, pre-calculated.</p></li>
<li><p><strong>ttp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a>, total negatives,
<a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a>, total positives, pre-calculated.</p></li>
<li><p><strong>negatives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for non-target and target samples</p></li>
<li><p><strong>positives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for non-target and target samples</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to compute the half-total error rate for.  Cannot be
<code class="docutils literal notranslate"><span class="pre">NaN</span></code> (not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>hter</strong> – The computed half-total error rate</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.jaccard_index">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">jaccard_index</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bob/measure/binary.html#jaccard_index"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bob.measure.binary.jaccard_index" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the Jaccard or Similarity index of a classifier</p>
<p>The Jaccard-index corresponds arithmetically:</p>
<div class="math notranslate nohighlight">
\begin{align*}
    \mathrm{J} &amp;= \frac{\mathrm{tp}}{\mathrm{fp}+\mathrm{tp}+\mathrm{fn}} \\
    \mathrm{J} &amp;= \frac{\mathrm{tp}}{\mathrm{fp}+\mathrm{ttp}}
\end{align*}</div><p>In the special case where <code class="docutils literal notranslate"><span class="pre">tn+fp+fn</span> <span class="pre">==</span> <span class="pre">0</span></code>, this function returns zero for
the Jaccard index.</p>
<p>The Jaccard index depends on a TP-only numerator, similarly to the F1
score.  This measure is not sensible to regions of the score domain where
no true-positives are available.  The <code class="docutils literal notranslate"><span class="pre">accuracy</span></code> may be a better proxy in
these cases.</p>
<p>This function has two signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">jaccard_index(fp,</span> <span class="pre">tp,</span> <span class="pre">ttp)</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">jaccard_index(negatives,</span> <span class="pre">positives,</span> <span class="pre">threshold)</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a>, <a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a> and
total positive scores, pre-calculated.</p></li>
<li><p><strong>tp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a>, <a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a> and
total positive scores, pre-calculated.</p></li>
<li><p><strong>ttp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a>, <a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a> and
total positive scores, pre-calculated.</p></li>
<li><p><strong>negatives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for non-target and target samples</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to compute the Jaccard index for.  Cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code>
(not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>jaccard_index</strong> – The computed Jaccard or Similarity index for the given scores and the
given threshold</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.jaccard">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">jaccard</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bob.measure.binary.jaccard" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the Jaccard or Similarity index of a classifier</p>
<p>The Jaccard-index corresponds arithmetically:</p>
<div class="math notranslate nohighlight">
\begin{align*}
    \mathrm{J} &amp;= \frac{\mathrm{tp}}{\mathrm{fp}+\mathrm{tp}+\mathrm{fn}} \\
    \mathrm{J} &amp;= \frac{\mathrm{tp}}{\mathrm{fp}+\mathrm{ttp}}
\end{align*}</div><p>In the special case where <code class="docutils literal notranslate"><span class="pre">tn+fp+fn</span> <span class="pre">==</span> <span class="pre">0</span></code>, this function returns zero for
the Jaccard index.</p>
<p>The Jaccard index depends on a TP-only numerator, similarly to the F1
score.  This measure is not sensible to regions of the score domain where
no true-positives are available.  The <code class="docutils literal notranslate"><span class="pre">accuracy</span></code> may be a better proxy in
these cases.</p>
<p>This function has two signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">jaccard_index(fp,</span> <span class="pre">tp,</span> <span class="pre">ttp)</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">jaccard_index(negatives,</span> <span class="pre">positives,</span> <span class="pre">threshold)</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a>, <a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a> and
total positive scores, pre-calculated.</p></li>
<li><p><strong>tp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a>, <a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a> and
total positive scores, pre-calculated.</p></li>
<li><p><strong>ttp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a>, <a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a> and
total positive scores, pre-calculated.</p></li>
<li><p><strong>negatives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for non-target and target samples</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to compute the Jaccard index for.  Cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code>
(not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>jaccard_index</strong> – The computed Jaccard or Similarity index for the given scores and the
given threshold</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.similarly_index">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">similarly_index</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bob.measure.binary.similarly_index" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the Jaccard or Similarity index of a classifier</p>
<p>The Jaccard-index corresponds arithmetically:</p>
<div class="math notranslate nohighlight">
\begin{align*}
    \mathrm{J} &amp;= \frac{\mathrm{tp}}{\mathrm{fp}+\mathrm{tp}+\mathrm{fn}} \\
    \mathrm{J} &amp;= \frac{\mathrm{tp}}{\mathrm{fp}+\mathrm{ttp}}
\end{align*}</div><p>In the special case where <code class="docutils literal notranslate"><span class="pre">tn+fp+fn</span> <span class="pre">==</span> <span class="pre">0</span></code>, this function returns zero for
the Jaccard index.</p>
<p>The Jaccard index depends on a TP-only numerator, similarly to the F1
score.  This measure is not sensible to regions of the score domain where
no true-positives are available.  The <code class="docutils literal notranslate"><span class="pre">accuracy</span></code> may be a better proxy in
these cases.</p>
<p>This function has two signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">jaccard_index(fp,</span> <span class="pre">tp,</span> <span class="pre">ttp)</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">jaccard_index(negatives,</span> <span class="pre">positives,</span> <span class="pre">threshold)</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a>, <a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a> and
total positive scores, pre-calculated.</p></li>
<li><p><strong>tp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a>, <a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a> and
total positive scores, pre-calculated.</p></li>
<li><p><strong>ttp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.false_positives" title="bob.measure.binary.false_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">false_positives()</span></code></a>, <a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a> and
total positive scores, pre-calculated.</p></li>
<li><p><strong>negatives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for non-target and target samples</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to compute the Jaccard index for.  Cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code>
(not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>jaccard_index</strong> – The computed Jaccard or Similarity index for the given scores and the
given threshold</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.matthews_correlation_coefficient">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">matthews_correlation_coefficient</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bob/measure/binary.html#matthews_correlation_coefficient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bob.measure.binary.matthews_correlation_coefficient" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the Matthews Correlation Coefficient (MCC) or Phi Coefficient of a classifier</p>
<p>The MCC corresponds arithmetically:</p>
<div class="math notranslate nohighlight">
\[\mathrm{MCC} = \frac{\mathrm{tp}\mathrm{tn} - \mathrm{fp}\mathrm{fn}}{\sqrt{(\mathrm{tp}+\mathrm{fp})(\mathrm{tp}+\mathrm{fn})(\mathrm{tn}+\mathrm{fp})(\mathrm{tn}+\mathrm{fn})}}\]</div>
<p>In the special case where the denominator is <code class="docutils literal notranslate"><span class="pre">0.0</span></code>, this function returns
zero for the MCC.</p>
<p>This function has two signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">matthews_correlation_coefficient(tn:</span> <span class="pre">int,</span> <span class="pre">ttn:</span> <span class="pre">int,</span> <span class="pre">tp:</span> <span class="pre">int,</span> <span class="pre">ttp:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">matthews_correlation_coefficient(negatives:</span> <span class="pre">Sequence[float],</span> <span class="pre">positives:</span> <span class="pre">Sequence[float],</span> <span class="pre">threshold:</span> <span class="pre">Sequence[float])</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a>, total negative scores,
<a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a> and total positive scores, pre-calculated.</p></li>
<li><p><strong>ttn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a>, total negative scores,
<a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a> and total positive scores, pre-calculated.</p></li>
<li><p><strong>tp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a>, total negative scores,
<a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a> and total positive scores, pre-calculated.</p></li>
<li><p><strong>ttp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a>, total negative scores,
<a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a> and total positive scores, pre-calculated.</p></li>
<li><p><strong>negatives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for non-target and target samples</p></li>
<li><p><strong>positives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for non-target and target samples</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to compute the MCC for.  Cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code>
(not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>mcc</strong> – The computed MCC of Phi Coefficient</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.phi_coefficient">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">phi_coefficient</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bob.measure.binary.phi_coefficient" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the Matthews Correlation Coefficient (MCC) or Phi Coefficient of a classifier</p>
<p>The MCC corresponds arithmetically:</p>
<div class="math notranslate nohighlight">
\[\mathrm{MCC} = \frac{\mathrm{tp}\mathrm{tn} - \mathrm{fp}\mathrm{fn}}{\sqrt{(\mathrm{tp}+\mathrm{fp})(\mathrm{tp}+\mathrm{fn})(\mathrm{tn}+\mathrm{fp})(\mathrm{tn}+\mathrm{fn})}}\]</div>
<p>In the special case where the denominator is <code class="docutils literal notranslate"><span class="pre">0.0</span></code>, this function returns
zero for the MCC.</p>
<p>This function has two signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">matthews_correlation_coefficient(tn:</span> <span class="pre">int,</span> <span class="pre">ttn:</span> <span class="pre">int,</span> <span class="pre">tp:</span> <span class="pre">int,</span> <span class="pre">ttp:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">matthews_correlation_coefficient(negatives:</span> <span class="pre">Sequence[float],</span> <span class="pre">positives:</span> <span class="pre">Sequence[float],</span> <span class="pre">threshold:</span> <span class="pre">Sequence[float])</span> <span class="pre">-&gt;</span> <span class="pre">float</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a>, total negative scores,
<a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a> and total positive scores, pre-calculated.</p></li>
<li><p><strong>ttn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a>, total negative scores,
<a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a> and total positive scores, pre-calculated.</p></li>
<li><p><strong>tp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a>, total negative scores,
<a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a> and total positive scores, pre-calculated.</p></li>
<li><p><strong>ttp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a>, total negative scores,
<a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a> and total positive scores, pre-calculated.</p></li>
<li><p><strong>negatives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for non-target and target samples</p></li>
<li><p><strong>positives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for non-target and target samples</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to compute the MCC for.  Cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code>
(not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>mcc</strong> – The computed MCC of Phi Coefficient</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)">float</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.measures">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">measures</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bob/measure/binary.html#measures"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bob.measure.binary.measures" title="Permalink to this definition">¶</a></dt>
<dd><p>In a single call, calculate most of the quantities in this module</p>
<p>This function simplifies the calculation of most performance measures in
this module through a single call.</p>
<p>This function accepts 2 signatures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">measures(tn:</span> <span class="pre">int,</span> <span class="pre">ttn:</span> <span class="pre">int,</span> <span class="pre">tp:</span> <span class="pre">int,</span> <span class="pre">ttp:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">Sequence[float]</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">measures(negatives:</span> <span class="pre">Sequence[float],</span> <span class="pre">positives:</span> <span class="pre">Sequence[float],</span> <span class="pre">threshold:</span> <span class="pre">float)</span> <span class="pre">-&gt;</span> <span class="pre">Sequence[float]</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a>, total negatives,
<a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a>, total positives, pre-calculated.</p></li>
<li><p><strong>ttn</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a>, total negatives,
<a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a>, total positives, pre-calculated.</p></li>
<li><p><strong>tp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a>, total negatives,
<a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a>, total positives, pre-calculated.</p></li>
<li><p><strong>ttp</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of <a class="reference internal" href="#bob.measure.binary.true_negatives" title="bob.measure.binary.true_negatives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_negatives()</span></code></a>, total negatives,
<a class="reference internal" href="#bob.measure.binary.true_positives" title="bob.measure.binary.true_positives"><code class="xref py py-func docutils literal notranslate"><span class="pre">true_positives()</span></code></a>, total positives, pre-calculated.</p></li>
<li><p><strong>negatives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for non-target and target samples</p></li>
<li><p><strong>positives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The scores for non-target and target samples</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The threshold to compute the accuracy for.  Cannot be <code class="docutils literal notranslate"><span class="pre">NaN</span></code>
(not-a-number).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>specificity</strong> (<em>float</em>) – Selectivity or true negative rate, see <a class="reference internal" href="#bob.measure.binary.specificity" title="bob.measure.binary.specificity"><code class="xref py py-func docutils literal notranslate"><span class="pre">specificity()</span></code></a></p></li>
<li><p><strong>recall</strong> (<em>float</em>) – Sensitivity, hit rate, or true positive rate, see <a class="reference internal" href="#bob.measure.binary.recall" title="bob.measure.binary.recall"><code class="xref py py-func docutils literal notranslate"><span class="pre">recall()</span></code></a></p></li>
<li><p><strong>precision</strong> (<em>float</em>) – Or Positive-Predictive Value (PPV), see <a class="reference internal" href="#bob.measure.binary.precision" title="bob.measure.binary.precision"><code class="xref py py-func docutils literal notranslate"><span class="pre">precision()</span></code></a></p></li>
<li><p><strong>f1_score</strong> (<em>float</em>) – See <a class="reference internal" href="#bob.measure.binary.f1_score" title="bob.measure.binary.f1_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">f1_score()</span></code></a></p></li>
<li><p><strong>accuracy</strong> (<em>float</em>) – See <a class="reference internal" href="#bob.measure.binary.accuracy" title="bob.measure.binary.accuracy"><code class="xref py py-func docutils literal notranslate"><span class="pre">accuracy()</span></code></a></p></li>
<li><p><strong>half_total_error_rate</strong> (<em>float</em>) – See <a class="reference internal" href="#bob.measure.binary.half_total_error_rate" title="bob.measure.binary.half_total_error_rate"><code class="xref py py-func docutils literal notranslate"><span class="pre">half_total_error_rate()</span></code></a></p></li>
<li><p><strong>jaccard_index</strong> (<em>float</em>) – See <a class="reference internal" href="#bob.measure.binary.jaccard_index" title="bob.measure.binary.jaccard_index"><code class="xref py py-func docutils literal notranslate"><span class="pre">jaccard_index()</span></code></a></p></li>
<li><p><strong>matthews_correlation_coefficient</strong> (<em>float</em>) – See <a class="reference internal" href="#bob.measure.binary.matthews_correlation_coefficient" title="bob.measure.binary.matthews_correlation_coefficient"><code class="xref py py-func docutils literal notranslate"><span class="pre">matthews_correlation_coefficient()</span></code></a></p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bob.measure.binary.eer">
<span class="sig-prename descclassname"><span class="pre">bob.measure.binary.</span></span><span class="sig-name descname"><span class="pre">eer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">negatives</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">positives</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_sorted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">also_farfrr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bob/measure/binary.html#eer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bob.measure.binary.eer" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the Equal Error Rate (EER)</p>
<p>Please note that it is possible that eer != fpr != fnr.  This function
returns (fpr + fnr) / 2 as eer.  If you also need the fpr and fnr values,
set <code class="docutils literal notranslate"><span class="pre">also_farfrr</span></code> to <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>negatives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The set of negative and positive scores to compute the measurement</p></li>
<li><p><strong>positives</strong> (<a class="reference external" href="https://numpy.org/doc/1.20/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><em>numpy.ndarray</em></a><em> (</em><em>1D</em><em>, </em><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – The set of negative and positive scores to compute the measurement</p></li>
<li><p><strong>is_sorted</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Are both sets of scores already in ascendantly sorted order?</p></li>
<li><p><strong>also_farfrr</strong> (<a class="reference external" href="https://docs.python.org/3.8/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – If True, it will also return far and frr.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>eer</strong> (<em>float</em>) – The Equal Error Rate (EER).</p></li>
<li><p><strong>fpr</strong> (<em>float</em>) – The False Positive Rate (FPR). Returned only when <code class="docutils literal notranslate"><span class="pre">also_farfrr</span></code> is
<code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><strong>fnr</strong> (<em>float</em>) – The False Negative Rate (FNR). Returned only when <code class="docutils literal notranslate"><span class="pre">also_farfrr</span></code> is
<code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../api.html" class="btn btn-neutral float-left" title="Python API" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="bob.measure.regression.html" class="btn btn-neutral float-right" title="bob.measure.regression" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Idiap Research Institute.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>